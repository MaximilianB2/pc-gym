{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome","title":"Welcome!","text":"<p>Process Control (pc-) gym is a set of benchmark chemical process control problems for reinforcement learning with integrated policy evaluation methods to aid the development of reinforcement learning algorithms.</p> <p>The pc-gym was developed within the Sargent Centre for Process Systems Engineering and is published as an open-source package which welcomes contributions from the RL and PSE communities.</p> <p>Note: this is a pre-release version of the documentation and may not reflect the current version of pc-gym</p>"},{"location":"#quick-start","title":"Quick start","text":"<p>Setup a CSTR environment with a setpoint change</p> <pre><code>import pcgym\n\n# Simulation variables\nnsteps = 100\nT = 25\n\n# Setpoint\nSP = {'Ca': [0.85 for i in range(int(nsteps/2))] + [0.9 for i in range(int(nsteps/2))]} \n\n# Action and observation Space\naction_space = {'low': np.array([295]), 'high': np.array([302])}\nobservation_space = {'low': np.array([0.7,300,0.8]),'high': np.array([1,350,0.9])}\n\n# Construct the environment parameter dictionary\nenv_params = {\n    'N': nsteps, # Number of time steps\n    'tsim':T, # Simulation Time\n    'SP' :SP, \n    'o_space' : observation_space, \n    'a_space' : action_space, \n    'x0': np.array([0.8, 330, 0.8]), # Initial conditions [Ca, T, Ca_SP]\n    'model': 'cstr_ode', # Select the model\n}\n\n# Create environment\nenv = pcgym.make_env(env_params)\n\n# Reset the environment\nobs, state = env.reset()\n\n# Sample a random action\naction = env.action_space.sample()\n\n# Perform a step in the environment\nobs, rew, done, term, info = env.step(action)\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>The latest production pc-gym version can be installed from PyPI:</p> <p><pre><code>pip install pcgym\n</code></pre> Alternatively, you can install the latest development version directly from GitHub:</p> <pre><code>pip install git+https://github.com/MaximilianB2/pc-gym\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<p>Example notebooks with training walkthroughs, implementing constraints, disturbances and the policy evaluation tool can be found here.</p>"},{"location":"#environments","title":"Environments","text":"<p>Currently there are six implemented process control environments, this will be expanded over time.</p> Environment Category Source Code Description CSTR Reactor Code Documentation First Order System Simple Model Code Documentation Multistage Extration Column Code Documentation Nonsmooth Control Linear System Code Documentation Crystallisation Reactor Reactor Code Documentation Four Tank System Level Control Code Documentation Fluidized Biofilm Sand Bed Reactor Reactor Code Documentation Photoproduction Bioreactor Code Documentation <p>All environments use the following observation representation for $i$ states and $j$ disturbances: \\begin{align} \\nonumber o = [x_i,..., x_{i,sp}..., d_j,...]  \\end{align}</p>"},{"location":"#future-features","title":"Future Features","text":"<p>The following features are being worked on to be added in the near future:  - Observability Mask   - More case studies  - Custom reward functions</p>"},{"location":"#citing-pc-gym","title":"Citing <code>pc-gym</code>","text":"<p>If you use <code>pc-gym</code> in your research, please cite using the following  <pre><code>@software{pcgym2024,\n  author = {Max Bloor and Jose Neto and Ilya Sandoval and Max Mowbray\n            and Akhil Ahmed and Mehmet Mercangoz and Calvin Tsay and Antonio Del Rio-Chanona},\n  title = {{pc-gym}: Reinforcement Learning Envionments for Process Control},\n  url = {https://github.com/MaximilianB2/pc-gym},\n  version = {0.0.4},\n  year = {2024},\n}\n</code></pre></p>"},{"location":"#other-great-gyms","title":"Other great gyms","text":"<p>Other works have built upon the OpenAI Gymnasium framework:</p> <ul> <li>\u2728safe-control-gym </li> <li>\u2728safety-gymnasium</li> <li>\u2728gymnax</li> </ul>"},{"location":"API/evaluation_metrics/","title":"Documentation for Policy Evaluation Metrics","text":""},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.reproducibility_metric","title":"<code>src.pcgym.evaluation_metrics.reproducibility_metric</code>","text":"<p>               Bases: <code>metric_base</code></p> <p>Class for calculating reproducibility metrics.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.reproducibility_metric.__init__","title":"<code>__init__(dispersion, performance, scalarised_weight)</code>","text":"<p>Initialize the reproducibility metric.</p> <p>Parameters:</p> Name Type Description Default <code>dispersion</code> <code>str</code> <p>The dispersion metric to use ('std' or 'mad').</p> required <code>performance</code> <code>str</code> <p>The performance metric to use ('mean' or 'median').</p> required <code>scalarised_weight</code> <code>float</code> <p>The weight for scalarised performance.</p> required"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.reproducibility_metric.evaluate","title":"<code>evaluate(policy_evaluator, component=None)</code>","text":"<p>Evaluate the given policy using the specified environment.</p> <p>Parameters:</p> Name Type Description Default <code>policy_evaluator</code> <code>Any</code> <p>The policy evaluator to generate data for a number of policy rollouts.</p> required <code>component</code> <code>Optional[str]</code> <p>The specific component to evaluate (optional).</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, ndarray]]</code> <p>The evaluation metric value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.reproducibility_metric.policy_dispersion_metric","title":"<code>policy_dispersion_metric(data, component)</code>","text":"<p>Evaluate the dispersion of the policy.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Dict[str, ndarray]]</code> <p>Nested dictionary containing policy data.</p> required <code>component</code> <code>Optional[str]</code> <p>The specific component to evaluate.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, ndarray]]</code> <p>The policy dispersion metric value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.reproducibility_metric.policy_performance_metric","title":"<code>policy_performance_metric(data, component)</code>","text":"<p>Evaluate the performance of the policy.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Dict[str, ndarray]]</code> <p>Nested dictionary containing policy data.</p> required <code>component</code> <code>Optional[str]</code> <p>The specific component to evaluate.</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, ndarray]]</code> <p>The policy performance metric value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.reproducibility_metric.scalarised_performance","title":"<code>scalarised_performance(data, component)</code>","text":"<p>Evaluate the scalarised performance of the policy.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Dict[str, ndarray]]</code> <p>Nested dictionary containing policy data.</p> required <code>component</code> <code>Optional[str]</code> <p>The specific component to evaluate (set to None to scalarise over all components).</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, ndarray]]</code> <p>The scalarised policy performance metric value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.reproducibility_metric.determine_op","title":"<code>determine_op(component)</code>","text":"<p>Determine the operation to be applied based on the component.</p> <p>Parameters:</p> Name Type Description Default <code>component</code> <code>str</code> <p>The component to determine the operation for.</p> required <p>Returns:</p> Type Description <code>Callable[[ndarray], ndarray]</code> <p>A lambda function representing the operation to be applied.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.metric_base","title":"<code>src.pcgym.evaluation_metrics.metric_base</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for policy evaluation metrics.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.metric_base.__init__","title":"<code>__init__(scalarised_weight)</code>","text":"<p>Initialize the metric base.</p> <p>Parameters:</p> Name Type Description Default <code>scalarised_weight</code> <code>float</code> <p>The weight for scalarised performance.</p> required"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.metric_base.evaluate","title":"<code>evaluate(policy_evaluator)</code>","text":"<p>Evaluate the given policy using the specified environment.</p> <p>Parameters:</p> Name Type Description Default <code>policy_evaluator</code> <code>Any</code> <p>The policy evaluator to generate data for a number of policy rollouts.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The evaluation metric value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.metric_base.policy_dispersion_metric","title":"<code>policy_dispersion_metric(data)</code>","text":"<p>Evaluate the dispersion of the policy.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>Nested dictionary containing policy data.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The policy dispersion metric value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.metric_base.policy_performance_metric","title":"<code>policy_performance_metric(data)</code>","text":"<p>Evaluate the performance of the policy.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>Nested dictionary containing policy data.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The policy performance metric value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.metric_base.scalarised_performance","title":"<code>scalarised_performance(data)</code>","text":"<p>Evaluate the scalarised performance of the policy.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>Nested dictionary containing policy data.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The scalarised policy performance metric value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.standard_deviation","title":"<code>src.pcgym.evaluation_metrics.standard_deviation</code>","text":"<p>Class for calculating standard deviation.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.standard_deviation.__init__","title":"<code>__init__(data)</code>","text":"<p>Initialize the standard deviation calculator.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data for standard deviation calculation.</p> required"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.standard_deviation.get_value","title":"<code>get_value()</code>","text":"<p>Calculate the standard deviation of the data.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The standard deviation value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.median_absolute_deviation","title":"<code>src.pcgym.evaluation_metrics.median_absolute_deviation</code>","text":"<p>Class for calculating median absolute deviation.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.median_absolute_deviation.__init__","title":"<code>__init__(data)</code>","text":"<p>Initialize the median absolute deviation calculator.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data for median absolute deviation calculation.</p> required"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.median_absolute_deviation.get_value","title":"<code>get_value()</code>","text":"<p>Calculate the median absolute deviation of the data.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The median absolute deviation value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.mean_performance","title":"<code>src.pcgym.evaluation_metrics.mean_performance</code>","text":"<p>Class for calculating mean performance.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.mean_performance.__init__","title":"<code>__init__(data)</code>","text":"<p>Initialize the mean performance calculator.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data for mean performance calculation.</p> required"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.mean_performance.get_value","title":"<code>get_value()</code>","text":"<p>Calculate the mean performance of the data.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The mean performance value.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.median_performance","title":"<code>src.pcgym.evaluation_metrics.median_performance</code>","text":"<p>Class for calculating median performance.</p>"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.median_performance.__init__","title":"<code>__init__(data)</code>","text":"<p>Initialize the median performance calculator.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data for median performance calculation.</p> required"},{"location":"API/evaluation_metrics/#src.pcgym.evaluation_metrics.median_performance.get_value","title":"<code>get_value()</code>","text":"<p>Calculate the median performance of the data.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The median performance value.</p>"},{"location":"API/integrator/","title":"Documentation for the Integrator","text":""},{"location":"API/integrator/#src.pcgym.integrator.integration_engine","title":"<code>src.pcgym.integrator.integration_engine</code>","text":"<p>Integration class that contains both the casadi and JAX integration wrappers.</p> <p>This class provides methods for integrating dynamical systems using either CasADi or JAX libraries.</p> <p>Attributes:</p> Name Type Description <code>env</code> <p>The environment object.</p> <code>integration_method</code> <p>The chosen integration method ('jax' or 'casadi').</p>"},{"location":"API/integrator/#src.pcgym.integrator.integration_engine.__init__","title":"<code>__init__(make_env, env_params)</code>","text":"<p>Initialize the integration engine.</p> <p>Parameters:</p> Name Type Description Default <code>make_env</code> <code>Callable</code> <p>A function to create the environment.</p> required <code>env_params</code> <code>Dict[str, Any]</code> <p>A dictionary of environment parameters.</p> required"},{"location":"API/integrator/#src.pcgym.integrator.integration_engine.jax_step","title":"<code>jax_step(state, uk)</code>","text":"<p>Integrate one time step using JAX.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ndarray</code> <p>The current state.</p> required <code>uk</code> <code>ndarray</code> <p>The control input.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The next state after integration.</p>"},{"location":"API/integrator/#src.pcgym.integrator.integration_engine.casadi_step","title":"<code>casadi_step(state, uk)</code>","text":"<p>Integrate one time step using CasADi.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ndarray</code> <p>The current state.</p> required <code>uk</code> <code>ndarray</code> <p>The control input.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The next state after integration.</p>"},{"location":"API/integrator/#src.pcgym.integrator.integration_engine.casadify","title":"<code>casadify(model, sym_x, sym_u)</code>","text":"<p>Convert a given model to CasADi symbolic form.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Callable</code> <p>The model to be converted.</p> required <code>sym_x</code> <code>SX</code> <p>Symbolic states.</p> required <code>sym_u</code> <code>SX</code> <p>Symbolic inputs.</p> required <p>Returns:</p> Type Description <code>SX</code> <p>CasADi symbolic model representing the right-hand side of the ODE.</p>"},{"location":"API/integrator/#src.pcgym.integrator.integration_engine.gen_casadi_variable","title":"<code>gen_casadi_variable(n_dim, name='x')</code>","text":"<p>Generate a CasADi symbolic variable.</p> <p>Parameters:</p> Name Type Description Default <code>n_dim</code> <code>int</code> <p>The dimension of the variable.</p> required <code>name</code> <code>str</code> <p>The name of the variable (default: \"x\").</p> <code>'x'</code> <p>Returns:</p> Type Description <code>SX</code> <p>A CasADi symbolic variable.</p>"},{"location":"API/integrator/#src.pcgym.integrator.integration_engine.gen_casadi_function","title":"<code>gen_casadi_function(casadi_input, casadi_output, name, input_name=[], output_name=[])</code>","text":"<p>Generate a CasADi function.</p> <p>Parameters:</p> Name Type Description Default <code>casadi_input</code> <code>List[SX]</code> <p>List of CasADi symbolic inputs.</p> required <code>casadi_output</code> <code>List[SX]</code> <p>List of CasADi symbolic outputs.</p> required <code>name</code> <code>str</code> <p>Name of the function.</p> required <code>input_name</code> <code>List[str]</code> <p>List of names for each input (optional).</p> <code>[]</code> <code>output_name</code> <code>List[str]</code> <p>List of names for each output (optional).</p> <code>[]</code> <p>Returns:</p> Type Description <code>Function</code> <p>A CasADi function mapping inputs to outputs.</p>"},{"location":"API/integrator/#src.pcgym.integrator.integration_engine.discretise_model","title":"<code>discretise_model(casadi_func, delta_t)</code>","text":"<p>Discretize a continuous-time CasADi model.</p> <p>Parameters:</p> Name Type Description Default <code>casadi_func</code> <code>Function</code> <p>The continuous-time CasADi function to be discretized.</p> required <code>delta_t</code> <code>float</code> <p>The time step for discretization.</p> required <p>Returns:</p> Type Description <code>Function</code> <p>A discretized CasADi function.</p>"},{"location":"API/make_env/","title":"Documentation for <code>make_env</code>","text":""},{"location":"API/make_env/#src.pcgym.pcgym.make_env","title":"<code>src.pcgym.pcgym.make_env</code>","text":"<p>               Bases: <code>Env</code></p>"},{"location":"API/make_env/#src.pcgym.pcgym.make_env.__init__","title":"<code>__init__(env_params)</code>","text":"<p>Initialize the environment with given parameters.</p> <p>Parameters:</p> Name Type Description Default <code>env_params</code> <code>dict</code> <p>Environment configuration parameters including model selection,                 spaces, simulation parameters, constraints, and custom functions.</p> required"},{"location":"API/make_env/#src.pcgym.pcgym.make_env.reset","title":"<code>reset(seed=0, **kwargs)</code>","text":"<p>Reset the environment to its initial state.</p> <p>This method resets the environment's state, time, and other relevant variables. It's called at the beginning of each episode.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Seed for random number generator.</p> <code>0</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[array, dict]</code> <p>A tuple containing: - numpy.array: The initial state observation. - dict: Additional information (e.g., initial reward).</p>"},{"location":"API/make_env/#src.pcgym.pcgym.make_env.step","title":"<code>step(action)</code>","text":"<p>Perform one time step in the environment.</p> <p>This method takes an action, applies it to the environment, and returns the next state, reward, and other information.</p> <p>Parameters:</p> Name Type Description Default <code>action</code> <code>array</code> <p>The action to be taken in the environment.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[array, float, bool, bool, dict]</code> <p>A tuple containing: - numpy.array: The next state observation. - float: The reward for the current step. - bool: Whether the episode has ended. - bool: Whether the episode was truncated. - dict: Additional information about the step.</p>"},{"location":"API/make_env/#src.pcgym.pcgym.make_env.con_checker","title":"<code>con_checker(curr_state, inputs)</code>","text":"<p>Check if any constraints are violated for the given states.</p> <p>Parameters:</p> Name Type Description Default <code>model_states</code> <code>list</code> <p>List of state or input names to check.</p> required <code>curr_state</code> <code>list</code> <p>List of corresponding state or input values.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if any constraint is violated, False otherwise.</p>"},{"location":"API/make_env/#src.pcgym.pcgym.make_env.constraint_check","title":"<code>constraint_check(state, input)</code>","text":"<p>Check if any constraints are violated in the current step.</p> <p>This method checks both state and input constraints, as well as any custom constraints defined by the user.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>array</code> <p>The current state of the system.</p> required <code>input</code> <code>array</code> <p>The current input (action) applied to the system.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if any constraint is violated, False otherwise.</p>"},{"location":"API/make_env/#src.pcgym.pcgym.make_env.get_rollouts","title":"<code>get_rollouts(policies, reps, oracle=False, dist_reward=False, MPC_params=False, cons_viol=False)</code>","text":"<p>Generate rollouts for the given policies.</p> <p>This method simulates the environment for multiple episodes using the provided policies.</p> <p>Parameters:</p> Name Type Description Default <code>policies</code> <code>dict</code> <p>Dictionary of policies to evaluate.</p> required <code>reps</code> <code>int</code> <p>Number of rollouts to perform.</p> required <code>oracle</code> <code>bool</code> <p>Whether to use an oracle model for evaluation. Defaults to False.</p> <code>False</code> <code>dist_reward</code> <code>bool</code> <p>Whether to use reward distribution. Defaults to False.</p> <code>False</code> <code>MPC_params</code> <code>bool</code> <p>Whether to use MPC parameters. Defaults to False.</p> <code>False</code> <code>cons_viol</code> <code>bool</code> <p>Whether to track constraint violations. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[policy_eval, dict]</code> <p>A tuple containing: - policy_eval: The policy evaluator object. - dict: Data from the rollouts.</p>"},{"location":"API/make_env/#src.pcgym.pcgym.make_env.plot_rollout","title":"<code>plot_rollout(policies, reps, oracle=False, dist_reward=False, MPC_params=False, cons_viol=False, save_fig=False)</code>","text":"<p>Generate and plot rollouts for the given policies.</p> <p>This method simulates the environment for multiple episodes using the provided policies and plots the results.</p> <p>Parameters:</p> Name Type Description Default <code>policies</code> <code>dict</code> <p>Dictionary of policies to evaluate.</p> required <code>reps</code> <code>int</code> <p>Number of rollouts to perform.</p> required <code>oracle</code> <code>bool</code> <p>Whether to use an oracle model for evaluation. Defaults to False.</p> <code>False</code> <code>dist_reward</code> <code>bool</code> <p>Whether to use reward distribution for plotting. Defaults to False.</p> <code>False</code> <code>MPC_params</code> <code>bool</code> <p>Whether to use MPC parameters. Defaults to False.</p> <code>False</code> <code>cons_viol</code> <code>bool</code> <p>Whether to track constraint violations. Defaults to False.</p> <code>False</code> <code>save_fig</code> <code>bool</code> <p>Whether to save the generated figures. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[policy_eval, dict]</code> <p>A tuple containing: - policy_eval: The policy evaluator object. - dict: Data from the rollouts.</p>"},{"location":"API/model_classes/","title":"Models","text":""},{"location":"API/model_classes/#src.pcgym.model_classes","title":"<code>src.pcgym.model_classes</code>","text":""},{"location":"API/model_classes/#src.pcgym.model_classes.cstr","title":"<code>cstr</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"API/model_classes/#src.pcgym.model_classes.first_order_system","title":"<code>first_order_system</code>  <code>dataclass</code>","text":"<p>First-order system model.</p> <p>Attributes:</p> Name Type Description <code>K</code> <code>float</code> <p>Gain</p> <code>tau</code> <code>float</code> <p>Time constant</p> <code>int_method</code> <code>str</code> <p>Integration method ('jax' or other)</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.first_order_system.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivative for the first-order system.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [x]</p> required <code>u</code> <code>ndarray</code> <p>Input [u]</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: State derivative [dx/dt]</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.first_order_system.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.multistage_extraction","title":"<code>multistage_extraction</code>  <code>dataclass</code>","text":"<p>Multistage extraction model.</p> <p>Attributes:</p> Name Type Description <code>Vl</code> <code>float</code> <p>Liquid volume in each stage</p> <code>Vg</code> <code>float</code> <p>Gas volume in each stage</p> <code>m</code> <code>float</code> <p>Equilibrium constant</p> <code>Kla</code> <code>float</code> <p>Mass transfer capacity constant (1/hr)</p> <code>eq_exponent</code> <code>float</code> <p>Nonlinearity of the equilibrium relationship</p> <code>X0</code> <code>float</code> <p>Feed concentration of liquid</p> <code>Y6</code> <code>float</code> <p>Feed concentration of gas</p> <code>int_method</code> <code>str</code> <p>Integration method ('jax' or other)</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.multistage_extraction.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the multistage extraction model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [X1, Y1, X2, Y2, X3, Y3, X4, Y4, X5, Y5]</p> required <code>u</code> <code>ndarray</code> <p>Input [L, G] or [L, G, X0, Y6]</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: State derivatives</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.multistage_extraction.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.nonsmooth_control","title":"<code>nonsmooth_control</code>  <code>dataclass</code>","text":"<p>Nonsmooth control model (Bang-Bang Control).</p> <p>Attributes:</p> Name Type Description <code>int_method</code> <code>str</code> <p>Integration method ('jax' or other)</p> <code>a_11,</code> <code>a_12, a_21, a_22 (float</code> <p>System matrix coefficients</p> <code>b_1,</code> <code>b_2 (float</code> <p>Input vector coefficients</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.nonsmooth_control.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the nonsmooth control model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [x1, x2]</p> required <code>u</code> <code>ndarray</code> <p>Input [u]</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: State derivatives [dx1/dt, dx2/dt]</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.nonsmooth_control.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.distillation_column","title":"<code>distillation_column</code>  <code>dataclass</code>","text":"<p>Distillation column model.</p> <p>Attributes:</p> Name Type Description <code>D</code> <code>float</code> <p>Distillate flow rate (kmol/hr)</p> <code>q</code> <code>float</code> <p>Feed quality (q=1 is saturated liquid)</p> <code>alpha</code> <code>float</code> <p>Relative volatility of more volatile component</p> <code>X_feed</code> <code>float</code> <p>Feed composition</p> <code>M0,</code> <code>Mb, M (float</code> <p>Holdup in different sections of the column</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.distillation_column.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the distillation column.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [X0, X1, X2, X3, Xf, X4, X5, X6, Xb]</p> required <code>u</code> <code>ndarray</code> <p>Input [R, F]</p> required <p>Returns:</p> Type Description <p>np.ndarray: State derivatives</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.distillation_column.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.cstr_series_recycle","title":"<code>cstr_series_recycle</code>  <code>dataclass</code>","text":"<p>CSTR series with recycle model.</p> <p>Attributes:</p> Name Type Description <code>C_O</code> <code>float</code> <p>Initial concentration (mol/m3)</p> <code>T_O</code> <code>float</code> <p>Initial temperature (K)</p> <code>V1,</code> <code>V2 (float</code> <p>Reactor volumes (m3)</p> <code>U1A1,</code> <code>U2A2 (float</code> <p>Heat transfer coefficients times areas (kJ/s*K)</p> <code>rho</code> <code>float</code> <p>Density (kg/m3)</p> <code>cp</code> <code>float</code> <p>Heat capacity (kJ/kg*K)</p> <code>k</code> <code>float</code> <p>Reaction rate constant (s-1)</p> <code>E</code> <code>float</code> <p>Activation energy (kJ/mol)</p> <code>deltaH</code> <code>float</code> <p>Heat of reaction (kJ/mol)</p> <code>R</code> <code>float</code> <p>Gas constant (kJ/mol K)</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.cstr_series_recycle.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the CSTR series with recycle.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [C1, T1, C2, T2]</p> required <code>u</code> <code>ndarray</code> <p>Input [F, L, Tc1, Tc2]</p> required <p>Returns:</p> Type Description <p>np.ndarray: State derivatives</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.cstr_series_recycle.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.multistage_extraction_reactive","title":"<code>multistage_extraction_reactive</code>  <code>dataclass</code>","text":"<p>Multistage extraction with reactive components model.</p> <p>Attributes:</p> Name Type Description <code>Vl</code> <code>float</code> <p>Liquid volume in each stage</p> <code>Vg</code> <code>float</code> <p>Gas volume in each stage</p> <code>m</code> <code>float</code> <p>Equilibrium constant</p> <code>Kla</code> <code>float</code> <p>Mass transfer capacity constant (1/hr)</p> <code>k</code> <code>float</code> <p>Reaction equilibrium constant</p> <code>eq_exponent</code> <code>float</code> <p>Nonlinearity of the equilibrium relationship</p> <code>XA0</code> <code>float</code> <p>Feed concentration of component A in liquid phase</p> <code>YA6,</code> <code>YB6, YC6 (float</code> <p>Feed concentrations in gas phase</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.multistage_extraction_reactive.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the multistage extraction with reactive components.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [XA1, YA1, YB1, YC1, XA2, YA2, YB2, YC2, XA3, YA3, YB3, YC3, XA4, YA4, YB4, YC4, XA5, YA5, YB5, YC5]</p> required <code>u</code> <code>ndarray</code> <p>Input [L, G]</p> required <p>Returns:</p> Type Description <p>np.ndarray: State derivatives</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.multistage_extraction_reactive.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.four_tank","title":"<code>four_tank</code>  <code>dataclass</code>","text":"<p>Four-tank system model.</p> <p>Attributes:</p> Name Type Description <code>g</code> <code>float</code> <p>Acceleration due to gravity (m/s2)</p> <code>gamma_1,</code> <code>gamma_2 (float</code> <p>Fraction bypassed by valves</p> <code>k1,</code> <code>k2 (float</code> <p>Pump gains (m3/Volts S)</p> <code>a1,</code> <code>a2, a3, a4 (float</code> <p>Cross-sectional areas of outlets (m2)</p> <code>A1,</code> <code>A2, A3, A4 (float</code> <p>Cross-sectional areas of tanks (m2)</p> <code>int_method</code> <code>str</code> <p>Integration method ('jax' or other)</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.four_tank.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the four-tank system.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [h1, h2, h3, h4]</p> required <code>u</code> <code>ndarray</code> <p>Input [v1, v2]</p> required <p>Returns:</p> Type Description <p>np.ndarray: State derivatives</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.four_tank.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.heat_exchanger","title":"<code>heat_exchanger</code>  <code>dataclass</code>","text":"<p>Heat exchanger model.</p> <p>Attributes:</p> Name Type Description <code>Utm</code> <code>float</code> <p>Tube-metal overall heat transfer coefficient (kW/m2 K)</p> <code>Usm</code> <code>float</code> <p>Shell-metal overall heat transfer coefficient (kW/m2 K)</p> <code>L</code> <code>float</code> <p>Length segment of each stage</p> <code>Dt</code> <code>float</code> <p>Internal diameter of tube wall (m)</p> <code>Dm</code> <code>float</code> <p>Outside diameter of metal wall (m)</p> <code>Ds</code> <code>float</code> <p>Shell wall diameter (m)</p> <code>cpt,</code> <code>cpm, cps (float</code> <p>Heat capacities (kJ/kg K)</p> <code>rhot,</code> <code>rhom, rhos (float</code> <p>Densities (kg/m3)</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.heat_exchanger.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the heat exchanger.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [Tt1, Tm1, Ts1, ..., Tt8, Tm8, Ts8]</p> required <code>u</code> <code>ndarray</code> <p>Input [Ft, Fs, Tt0, Ts9]</p> required <p>Returns:</p> Type Description <p>np.ndarray: State derivatives</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.heat_exchanger.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.biofilm_reactor","title":"<code>biofilm_reactor</code>  <code>dataclass</code>","text":"<p>Biofilm reactor model.</p> <p>Attributes:</p> Name Type Description <code>V</code> <code>float</code> <p>Volume of one reactor stage (L)</p> <code>Va</code> <code>float</code> <p>Volume of absorber tank (L)</p> <code>Kla</code> <code>float</code> <p>Transfer coefficient (hr)</p> <code>m</code> <code>float</code> <p>Equilibrium constant</p> <code>eq_exponent</code> <code>float</code> <p>Nonlinearity of equilibrium relationship</p> <code>O_air</code> <code>float</code> <p>Concentration of oxygen in air (mg/L)</p> <code>vm_1,</code> <code>vm_2 (float</code> <p>Maximum velocities through fluidized bed (mg/L hr)</p> <code>K1,</code> <code>K2 (float</code> <p>Equilibrium constants for reactions</p> <code>KO_1,</code> <code>KO_2 (float</code> <p>Equilibrium constants for oxygen</p> <code>int_method</code> <code>str</code> <p>Integration method ('jax' or other)</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.biofilm_reactor.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the biofilm reactor.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [S1_1, S2_1, S3_1, O_1, ..., S1_A, S2_A, S3_A, O_A]</p> required <code>u</code> <code>ndarray</code> <p>Input [F, Fr, S1_F, S2_F, S3_F]</p> required <p>Returns:</p> Type Description <p>np.ndarray: State derivatives</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.biofilm_reactor.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.polymerisation_reactor","title":"<code>polymerisation_reactor</code>  <code>dataclass</code>","text":"<p>Polymerisation reactor model.</p> <p>Attributes:</p> Name Type Description <code>Ap,</code> <code>Ad, At (float</code> <p>Pre-exponential factors (1/sec)</p> <code>Ep_over_R,</code> <code>Ed_over_R, Et_over_R (float</code> <p>Activation energies over R (K)</p> <code>f</code> <code>float</code> <p>Reactivity fraction for free radicals</p> <code>V</code> <code>float</code> <p>Reactor volume (m3)</p> <code>deltaHp</code> <code>float</code> <p>Heat of reaction per monomer unit (kJ/kmol)</p> <code>rho</code> <code>float</code> <p>Density of input fluid mixture (kg/m3)</p> <code>cp</code> <code>float</code> <p>Heat capacity of fluid mixture (kj/kg K)</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.polymerisation_reactor.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the polymerisation reactor.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state [T, M, I]</p> required <code>u</code> <code>ndarray</code> <p>Input [F, Tf, Mf, If]</p> required <p>Returns:</p> Type Description <p>np.ndarray: State derivatives</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.polymerisation_reactor.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing model parameters, states, inputs, and disturbances.</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.crystallization","title":"<code>crystallization</code>  <code>dataclass</code>","text":"<p>Crystallization of K2SO4 Control (PBE Model).</p> <p>This model represents a highly nonlinear crystallization process based on population balance equations (PBE). It simulates the evolution of crystal size distribution and concentration during the crystallization process.</p> <p>Attributes:</p> Name Type Description <code>ka</code> <code>float</code> <p>Nucleation rate constant</p> <code>kb</code> <code>float</code> <p>Nucleation activation energy parameter</p> <code>kc</code> <code>float</code> <p>Nucleation supersaturation exponent</p> <code>kd</code> <code>float</code> <p>Nucleation crystal density exponent</p> <code>kg</code> <code>float</code> <p>Growth rate constant</p> <code>k1</code> <code>float</code> <p>Growth activation energy parameter</p> <code>k2</code> <code>float</code> <p>Growth supersaturation exponent</p> <code>a</code> <code>float</code> <p>Moment model parameter for nucleation</p> <code>b</code> <code>float</code> <p>Moment model parameter for growth</p> <code>alfa</code> <code>float</code> <p>Shape factor for volume calculation</p> <code>ro</code> <code>float</code> <p>Crystal density (g/cm^3)</p> <code>int_method</code> <code>str</code> <p>Integration method ('jax' or other)</p> Reference <p>https://pubs.acs.org/doi/10.1021/acs.iecr.3c00739</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.crystallization.__call__","title":"<code>__call__(x, u)</code>","text":"<p>Calculate the state derivatives for the crystallization model.</p> <p>This method computes the rates of change for the moments of the crystal size distribution and the solute concentration based on the current state and input temperature.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Current state vector containing: - mu0 (float): 0th moment of crystal size distribution - mu1 (float): 1st moment of crystal size distribution - mu2 (float): 2nd moment of crystal size distribution - mu3 (float): 3rd moment of crystal size distribution - conc (float): Solute concentration</p> required <code>u</code> <code>ndarray</code> <p>Input vector containing: - T (float): Temperature (\u00b0C)</p> required <p>Returns:</p> Type Description <p>np.ndarray: State derivatives vector containing: - dmu0/dt: Rate of change of 0th moment - dmu1/dt: Rate of change of 1st moment - dmu2/dt: Rate of change of 2nd moment - dmu3/dt: Rate of change of 3rd moment - dconc/dt: Rate of change of solute concentration</p>"},{"location":"API/model_classes/#src.pcgym.model_classes.crystallization.info","title":"<code>info()</code>","text":"<p>Get model information.</p> <p>This method returns a dictionary containing information about the model's parameters, states, inputs, and disturbances.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing: - parameters: Model parameters - states: Names of state variables - inputs: Names of input variables - disturbances: Names of disturbance variables (if any)</p>"},{"location":"API/oracle/","title":"Oracle","text":""},{"location":"API/oracle/#src.pcgym.oracle.oracle","title":"<code>src.pcgym.oracle.oracle</code>","text":""},{"location":"API/oracle/#src.pcgym.oracle.oracle.__init__","title":"<code>__init__(env, env_params, MPC_params=False)</code>","text":""},{"location":"API/oracle/#src.pcgym.oracle.oracle.mpc","title":"<code>mpc()</code>","text":""},{"location":"API/policy_evaluation/","title":"Policy Evaluation","text":""},{"location":"API/policy_evaluation/#src.pcgym.policy_evaluation.policy_eval","title":"<code>src.pcgym.policy_evaluation.policy_eval</code>","text":"<p>Policy Evaluation Class for pc-gym.</p> <p>This class provides methods for evaluating policies in a given environment, including rollouts, oracle comparisons, and data visualization.</p> <p>Attributes:</p> Name Type Description <code>make_env</code> <p>Callable Function to create the environment.</p> <code>env_params</code> <p>dict Parameters for the environment.</p> <code>env</code> <p>Environment The environment instance.</p> <code>policies</code> <p>dict Dictionary of policies to evaluate.</p> <code>n_pi</code> <p>int Number of policies.</p> <code>reps</code> <p>int Number of repetitions for evaluation.</p> <code>oracle</code> <p>bool Whether to use oracle comparisons.</p> <code>cons_viol</code> <p>bool Whether to plot constraint violations.</p> <code>save_fig</code> <p>bool Whether to save generated figures.</p> <code>MPC_params</code> <p>dict or bool Parameters for MPC, if applicable.</p>"},{"location":"API/policy_evaluation/#src.pcgym.policy_evaluation.policy_eval.__init__","title":"<code>__init__(make_env, policies, reps, env_params, oracle=False, MPC_params=False, cons_viol=False, save_fig=False)</code>","text":"<p>Initialize the policy_eval class.</p> <p>Parameters:</p> Name Type Description Default <code>make_env</code> <code>callable</code> <p>Function to create the environment.</p> required <code>policies</code> <code>dict</code> <p>Dictionary of policies to evaluate.</p> required <code>reps</code> <code>int</code> <p>Number of repetitions for evaluation.</p> required <code>env_params</code> <code>dict</code> <p>Parameters for the environment.</p> required <code>oracle</code> <code>bool</code> <p>Whether to use oracle comparisons. Defaults to False.</p> <code>False</code> <code>MPC_params</code> <code>dict</code> <p>Parameters for MPC, if applicable. Defaults to False.</p> <code>False</code> <code>cons_viol</code> <code>bool</code> <p>Whether to plot constraint violations. Defaults to False.</p> <code>False</code> <code>save_fig</code> <code>bool</code> <p>Whether to save generated figures. Defaults to False.</p> <code>False</code>"},{"location":"API/policy_evaluation/#src.pcgym.policy_evaluation.policy_eval.rollout","title":"<code>rollout(policy_i)</code>","text":"<p>Rollout the policy for N steps and return the total reward, states and actions.</p> <p>Parameters:</p> Name Type Description Default <code>policy_i</code> <p>Policy to be rolled out.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>Containing: - total_reward (list): Total reward obtained. - s_rollout (np.ndarray): States obtained from rollout. - actions (np.ndarray): Actions obtained from rollout. - cons_info (np.ndarray): Constraint information.</p>"},{"location":"API/policy_evaluation/#src.pcgym.policy_evaluation.policy_eval.oracle_reward_fn","title":"<code>oracle_reward_fn(x, u)</code>","text":"<p>Calculate the oracle reward for given states and actions.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>State trajectory.</p> required <code>u</code> <code>ndarray</code> <p>Action trajectory.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>Oracle rewards for each time step.</p>"},{"location":"API/policy_evaluation/#src.pcgym.policy_evaluation.policy_eval.get_rollouts","title":"<code>get_rollouts()</code>","text":"<p>Perform rollouts for all policies and collect data.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary containing rollout data for each policy and oracle (if applicable).</p>"},{"location":"API/policy_evaluation/#src.pcgym.policy_evaluation.policy_eval.plot_data","title":"<code>plot_data(data, reward_dist=False)</code>","text":"<p>Plot the rollout data for all policies.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing rollout data.</p> required <code>reward_dist</code> <code>bool</code> <p>Whether to plot reward distribution. Defaults to False.</p> <code>False</code>"},{"location":"env/biofilm/","title":"Biofilm","text":""},{"location":"env/biofilm/#description-equations","title":"Description &amp; Equations","text":"<p>The fluidized biofilm sand bed reactor is a critical unit operation in biological wastewater treatment that enables the removal of nitrogen (in the form of ammonium) through sequential oxidation reactions. The process involves a three-stage reactor system coupled with an absorber, described by coupled differential equations representing the dynamic concentration changes of multiple species:</p> <p>For each reactor stage n:</p> <p>\\begin{align} \\frac{dS_{1n}}{dt} &amp;= \\frac{q_r}{V}(S_{1,n-1} - S_{1n}) - \\frac{v_{max1}S_{1n}O_n}{(K_1 + S_{1n})(K_{O1} + O_n)} \\ \\frac{dS_{2n}}{dt} &amp;= \\frac{q_r}{V}(S_{2,n-1} - S_{2n}) + \\frac{v_{max1}S_{1n}O_n}{(K_1 + S_{1n})(K_{O1} + O_n)} - \\frac{v_{max2}S_{2n}O_n}{(K_2 + S_{2n})(K_{O2} + O_n)} \\ \\frac{dS_{3n}}{dt} &amp;= \\frac{q_r}{V}(S_{3,n-1} - S_{3n}) + \\frac{v_{max2}S_{2n}O_n}{(K_2 + S_{2n})(K_{O2} + O_n)} \\ \\frac{dO_n}{dt} &amp;= \\frac{q_r}{V}(O_{n-1} - O_n) - 3.5\\frac{v_{max1}S_{1n}O_n}{(K_1 + S_{1n})(K_{O1} + O_n)} - 1.1\\frac{v_{max2}S_{2n}O_n}{(K_2 + S_{2n})(K_{O2} + O_n)} \\end{align}</p> <p>For the absorber:</p> <p>\\begin{align} \\frac{dS_{1A}}{dt} &amp;= \\frac{q_r}{V}(S_{13} - S_{1A}) + \\frac{q}{V_A}(S_{1F} - S_{1A}) \\ \\frac{dS_{2A}}{dt} &amp;= \\frac{q_r}{V}(S_{23} - S_{2A}) + \\frac{q}{V_A}(S_{2F} - S_{2A}) \\ \\frac{dS_{3A}}{dt} &amp;= \\frac{q_r}{V}(S_{33} - S_{3A}) + \\frac{q}{V_A}(S_{3F} - S_{3A}) \\ \\frac{dO_A}{dt} &amp;= \\frac{q_r}{V}(O_3 - O_A) + K_{La}(mO_{Air} - O_A) \\end{align}</p> <p>Where the concentrations of ammonium ($S_1$), nitrite ($S_2$), nitrate ($S_3$), and oxygen ($O$) in each stage and the absorber are the state variables, $\\mathbf{x} \\in \\mathbb{R}^{16}$. The action variables are the recycle flowrate, feed flowrate, and feed concentrations to the absorber, $\\mathbf{u} = [q_r, q, S_{1F}, S_{2F}, S_{3F}]^\\intercal \\in \\mathbb{R}^5$.</p>"},{"location":"env/biofilm/#observation","title":"Observation","text":"<p>The observation of the <code>Biofilm Reactor</code> environment provides information on the concentrations of the three nitrogen species at the outlet of the reactor, $\\mathbf{y} = [S_{13}, S_{23}, S_{33}]^\\intercal \\in \\mathbb{R}^3$. The observation space is defined by the following bounds:</p> <p><pre><code>[[0,10],[0,10],[0,10],[0,500],[0,10],[0,10],[0,10],[0,500],[0,10],[0,10],[0,10],[0,500],[0,10],[0,10],[0,10],[0,500],[0.9,1.1]]\n</code></pre> An example, tested set of initial conditions are as follows: <pre><code>[2,0.1,10,0.1,2,0.1,10,0.1,2,0.1,10,0.1,2,0.1,10,0.1,1]\n</code></pre></p>"},{"location":"env/biofilm/#action","title":"Action","text":"<p>The action space is a <code>ContinuousBox</code> with bounds: <pre><code>[[0.0,10.0],    # Recycle flowrate (L/hr)\n [1.0,30.0],    # Feed flowrate (L/hr)\n [0.05,1.0],    # Feed ammonium concentration (mg/L)\n [0.05,1.0],    # Feed nitrite concentration (mg/L)\n [0.05,1.0]]    # Feed nitrate concentration (mg/L)\n</code></pre></p>"},{"location":"env/biofilm/#parameters","title":"Parameters","text":"<p>The system parameters are defined as follows: <pre><code>{\n    'V': 10.0,      # Volume of Reactor Stage (L)\n    'VA': 15.0,     # Volume of Absorber (L)\n    'KLa': 1.5,     # Mass Transfer Constant (1/hr)\n    'OAir': 300,    # Concentration of Oxygen in Air (mg/L)\n    'K1': 0.5,      # Ammonia Saturation Constant for Reaction 1 (mg/L)\n    'K2': 0.1,      # Ammonia Saturation Constant for Reaction 2 (mg/L)\n    'KO1': 1.5,     # Oxygen Saturation Constant for Reaction 1 (mg/L)\n    'KO2': 0.5,     # Oxygen Saturation Constant for Reaction 2 (mg/L)\n    'vmax1': 0.8,   # Maximum Velocity Through Bed for Reaction 1 (mg/L hr)\n    'vmax2': 1.0,   # Maximum Velocity Through Bed for Reaction 2 (mg/L hr)\n    'm': 0.5        # Equilibrium Constant (-)\n}\n</code></pre></p>"},{"location":"env/biofilm/#reference","title":"Reference","text":"<p>This model and its description were kindly provided by Akhil Ahmed. The original model was created by Tanaka &amp; Dunn (1982). This documentation was created by Tom Savage.</p>"},{"location":"env/crystallisation/","title":"Crystallisation","text":""},{"location":"env/crystallisation/#potassium-sulfate-crystallization-model","title":"Potassium Sulfate Crystallization Model","text":""},{"location":"env/crystallisation/#overview","title":"Overview","text":"<p>Model describes K$_2$SO$_4$ crystallization using method of moments, tracking crystal size distribution moments (\u03bc$_0$-\u03bc$_3$) and solute concentration (c).</p>"},{"location":"env/crystallisation/#core-equations","title":"Core Equations","text":"<p>\\begin{align} \\frac{d\\mu_0}{dt} &amp;= B_0 \\ \\frac{d\\mu_1}{dt} &amp;= G_{\\infty} (a\\mu_0 + b\\mu_1 \\times 10^{-4}) \\times 10^4 \\ \\frac{d\\mu_2}{dt} &amp;= 2G_{\\infty} (a\\mu_1 \\times 10^{-4} + b\\mu_2 \\times 10^{-8}) \\times 10^8 \\ \\frac{d\\mu_3}{dt} &amp;= 3G_{\\infty} (a\\mu_2 \\times 10^{-8} + b\\mu_3 \\times 10^{-12}) \\times 10^{12} \\ \\frac{dc}{dt} &amp;= -0.5\\rho\\alpha G_{\\infty} (a\\mu_2 \\times 10^{-8} + b\\mu_3 \\times 10^{-12}) \\end{align}</p>"},{"location":"env/crystallisation/#rate-dependencies","title":"Rate Dependencies","text":"<p>\\begin{align} C_{eq} &amp;= -686.2686 + 3.579165(T+273.15) - 0.00292874(T+273.15)^2 \\ S &amp;= c \\times 10^3 - C_{eq} \\ B_0 &amp;= k_a \\exp\\left(\\frac{k_b}{T+273.15}\\right) (S^2)^{k_c/2} (\\mu_3^2)^{k_d/2} \\ G_{\\infty} &amp;= k_g \\exp\\left(\\frac{k_1}{T+273.15}\\right) (S^2)^{k_2/2} \\end{align}</p>"},{"location":"env/crystallisation/#key-parameters","title":"Key Parameters","text":"<ul> <li>Nucleation: $k_a$=0.92, $k_b$=-6800, $k_c$=0.92, $k_d$=1.3</li> <li>Growth: $k_g$=48, $k_1$=-4900, $k_2$=1.9</li> <li>Size-dependent: a=0.51, b=7.3</li> <li>Physical: \u03b1=7.5, \u03c1=2.7 g/cm$^3$</li> </ul> <p>Temperature (T) serves as control variable to achieve desired crystal size distribution.</p>"},{"location":"env/crystallisation/#observation","title":"Observation","text":"<p>The observation of the <code>crystallisation</code> environment provides information on the state variables and their associated setpoints (if they exist) at the current timestep. The observation is an array of shape <code>(1, 7 + N_SP)</code> where <code>N_SP</code> is the number of setpoints. Therefore, the observation when there a setpoint exists for $CV$ and $Ln$ is <code>[mu0, mu1, mu2, mu3, conc, CV, Ln, CV_SP, Ln_SP]</code>.</p> <p>The observation space is defined by the following bounds corresponding to the ordered state variables: <pre><code>[[0, 1e20], [0, 1e20], [0, 1e20], [0, 1e20], [0, 0.5], [0, 2], [0, 20], [0.9, 1.1], [14, 16]]\n</code></pre> An example, tested set of initial conditions are as follows: <pre><code>[1478.01, 22995.82, 1800863.24, 248516167.94, 0.1586, 0.5, 15, 1, 15]\n</code></pre></p>"},{"location":"env/crystallisation/#action","title":"Action","text":"<p>The action space is a <code>ContinuousBox</code> of <code>[[-1],[1]]</code> which corresponds to a change in cooling temperature.</p>"},{"location":"env/crystallisation/#reward","title":"Reward","text":"<p>The reward is a continuous value corresponding to square error of the state and its setpoint. For multiple states, these are scaled with a factor (<code>r_scale</code>)and summed to give a single value.</p>"},{"location":"env/crystallisation/#reference","title":"Reference","text":"<p>The original model was created by de Moraes et. al. (2023).</p>"},{"location":"env/cstr/","title":"Continuously Stirred Tank Reactor","text":""},{"location":"env/cstr/#description-equations","title":"Description &amp; Equations","text":"<p>The continuously stirred tank reactor (CSTR) is a system which converts species A to species B via the reaction: A  \u2192  B. The reactor's temperature is controlled by a cooling jacket. The following system of equations describes the system:</p> <p>\\begin{align}   \\nonumber\\frac{\\mathrm{d}C_A}{\\mathrm{d}t} &amp;= \\frac{q}{V}(C_{A_f} - C_A) - kC_Ae^{\\frac{-E_A}{RT}}\\ \\end{align} \\begin{align}   \\nonumber\\frac{\\mathrm{d}T}{\\mathrm{d}t} &amp;= \\frac{q}{V}(T_f - T) -\\frac{\\Delta H_R}{\\rho C_p}kC_Ae^{\\frac{-E_A}{RT}} + \\frac{UA}{\\rho C_p V}(T_c - T) \\end{align} where $C_A$, the concentration of species A in the reactor, and $T$, the temperature of the reactor, are the state variables, $\\mathbf{x} = [C_A, T]^\\intercal \\in \\mathbb{R}^2$ while, $u = T_c$, the cooling water temperature, is the action variable.</p>"},{"location":"env/cstr/#observation","title":"Observation","text":"<p>The observation of the <code>CSTR</code> environment provides information on the state variables and their associated setpoints (if they exist) at the current timestep. The observation is an array of shape <code>(1, 2 + N_SP)</code> where <code>N_SP</code> is the number of setpoints. Therefore, the observation when there exist a setpoint for both states is <code>[CA, T, CA_Setpoint, T_Setpoint]</code>.</p> <p>The observation space is defined by the following bounds corresponding to the ordered state variables: <pre><code>[[0.7,1],[300,350],[0.8,0.9]]\n</code></pre> An example, tested set of initial conditions are as follows: <pre><code>[0.8,330,0.8]\n</code></pre></p>"},{"location":"env/cstr/#action","title":"Action","text":"<p>The action space is a <code>ContinuousBox</code> of <code>[290,302]</code> which corresponds to a jacket temperature between 290 K and 302 K.</p>"},{"location":"env/cstr/#reward","title":"Reward","text":"<p>The reward is a continuous value corresponding to square error of the state and its setpoint. For multiple states, these are scaled with a factor (<code>r_scale</code>) and summed to give a single value.</p>"},{"location":"env/cstr/#reference","title":"Reference","text":"<p>This model implementation and its description were kindly provided by Akhil Ahmed. The original model was created by by Hedengren (2022).</p>"},{"location":"env/extraction-column/","title":"Extraction Column","text":""},{"location":"env/extraction-column/#description-equations","title":"Description &amp; Equations","text":"<p>The multistage extraction column is a key unit operation in chemical engineering that enables mass transfer between liquid and gas phases across multiple theoretical stages, described by coupled differential equations representing the dynamic concentration changes in each phase:</p> <p>\\begin{align}   \\nonumber\\frac{\\mathrm{d}X_i}{\\mathrm{d}t} &amp;= \\frac{L}{V_L}(X_{i-1}-X_i) - K_{La}\\left(X_i - \\frac{Y_i}{m}\\right)\\ \\end{align} \\begin{align}   \\nonumber\\frac{\\mathrm{d}Y_i}{\\mathrm{d}t} &amp;= \\frac{G}{V_G}(Y_{i+1}-Y_i) + K_{La}\\left(X_i - \\frac{Y_i}{m}\\right)\\ \\end{align}</p> <p>Where the concentration of the solute in the liquid and gas at each stage, $X_i$ and $Y_i$ are the state variables, $\\mathbf{x} = [X_1..X_{10},Y_1...Y_{10}]^\\intercal  \\in \\mathbb{R}^{10}$. The action variables are the flowrate of the gas and liquid phases through the column, $\\mathbf{u} = [L, G]^\\intercal \\in \\mathbb{R}^2$.</p>"},{"location":"env/extraction-column/#observation","title":"Observation","text":"<p>The observation of the <code>Multistage Extraction</code> environment provides information on the state variables and their associated setpoints (if they exist) at the current timestep. The observation is an array of shape <code>(1, 10 + N_SP)</code> where <code>N_SP</code> is the number of setpoints. Therefore, the observation when there a setpoint exists for $X_1$ and $Y_1$ is <code>[X_n..., Y_n..., X_1, Y_1]</code>.</p> <p>The observation space is defined by the following bounds corresponding to the ordered state variables:  <pre><code>[[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0.3,0.4]]\n</code></pre> An example, tested set of initial conditions are as follows: <pre><code>[0.55, 0.3, 0.45, 0.25, 0.4, 0.20, 0.35, 0.15, 0.25, 0.1,0.3]\n</code></pre></p>"},{"location":"env/extraction-column/#action","title":"Action","text":"<p>The action space is a <code>ContinuousBox</code> of <code>[[5,10],[500,1000]]</code> which corresponds to a liquid phase flowrate between 5 m$^3$/hr and 500 m$^3$/hr and a gas phase flowrate between 10 m$^3$/hr and 1000 m$^3$/hr.</p>"},{"location":"env/extraction-column/#reward","title":"Reward","text":"<p>The reward is a continuous value corresponding to square error of the state and its setpoint. For multiple states, these are scaled with a factor (<code>r_scale</code>)and summed to give a single value.</p>"},{"location":"env/extraction-column/#reference","title":"Reference","text":"<p>This model and its description were kindly provided by Akhil Ahmed. The original model was created by Ingham et. al. (2007).</p>"},{"location":"env/first_order_system/","title":"First Order System","text":""},{"location":"env/first_order_system/#description-equations","title":"Description &amp; Equations","text":"<p>The first order system is an environment which could represent many first order systems in engineering. It is included as a simple environment to use in the initial development of control algorithms. The following system of equations describes the system</p> <p>\\begin{align}   \\nonumber\\frac{\\mathrm{d}x}{\\mathrm{d}t} &amp;= \\frac{Ku-x}{\\tau}\\ \\end{align}</p> <p>where $x$, is the state variable, $\\mathbf{x} \\in \\mathbb{R}^2$ while, $u$ is the action variable.</p>"},{"location":"env/first_order_system/#observation","title":"Observation","text":"<p>The observation of the <code>First Order System</code> environment provides information on the state variables and their associated setpoints (if they exist) at the current timestep. The observation is an array of shape <code>(1, 1 + N_SP)</code> where <code>N_SP</code> is the number of setpoints. Therefore, the observation when there a setpoint exists <code>[x, x_Setpoint]</code>.</p>"},{"location":"env/first_order_system/#action","title":"Action","text":"<p>The action space is a <code>ContinuousBox</code> of <code>[0,10]</code>.</p>"},{"location":"env/first_order_system/#reward","title":"Reward","text":"<p>The reward is a continuous value corresponding to square error of the state and its setpoint. For multiple states, these are scaled with a factor $\\gamma_i$ and summed to give a single value.</p>"},{"location":"env/first_order_system/#reference","title":"Reference","text":"<p>This model implementation and its description were kindly provided by Akhil Ahmed. </p>"},{"location":"env/four_tank/","title":"Four tank","text":""},{"location":"env/four_tank/#four-tank-system","title":"Four Tank System","text":"<p>The four-tank system is a multivariable process consisting of four interconnected water tanks. This system is often used as a benchmark for control systems due to its nonlinear dynamics and the coupling between inputs and outputs. The model describes the change in water levels in each tank based on the inflows and outflows. \\begin{align} \\frac{dh_1}{dt} &amp;= -\\frac{a_1}{A_1}\\sqrt{2g_ah_1} + \\frac{a_3}{A_1}\\sqrt{2g_ah_3} + \\frac{\\gamma_1 k_1}{A_1}v_1 \\ \\frac{dh_2}{dt} &amp;= -\\frac{a_2}{A_2}\\sqrt{2g_ah_2} + \\frac{a_4}{A_2}\\sqrt{2g_ah_4} + \\frac{\\gamma_2 k_2}{A_2}v_2 \\ \\frac{dh_3}{dt} &amp;= -\\frac{a_3}{A_3}\\sqrt{2g_ah_3} + \\frac{(1-\\gamma_2)k_2}{A_3}v_2 \\ \\frac{dh_4}{dt} &amp;= -\\frac{a_4}{A_4}\\sqrt{2g_ah_4} + \\frac{(1-\\gamma_1)k_1}{A_4}v_1 \\end{align}</p>"},{"location":"env/four_tank/#observation-space","title":"Observation Space","text":"<p>The observation of the <code>four_tank</code> environment provides information on the state variables and their associated setpoints (if they exist) at the current timestep. The observation is an array of shape <code>(1, 4 + N_SP)</code> where <code>N_SP</code> is the number of setpoints. Therefore, the observation when there a setpoint exists for $h3_SP$ and $h4_SP$ is <code>[h1, h2, h3, h4, h3_SP, h4_SP]</code>.</p> <p>The observation space is defined by the following bounds corresponding to the ordered state variables:  <pre><code>[[0,0.6],[0,0.6],[0,0.6],[0,0.6],[0,0.6],[0,0.6]]\n</code></pre> An example, tested set of initial conditions are as follows: <pre><code>[0.141, 0.112, 0.072, 0.42, 0.5, 0.2]\n</code></pre></p>"},{"location":"env/four_tank/#action-space","title":"Action Space","text":"<p>The action space consists of two variables (v_1 &amp; v_2) which represent the voltages to the respective pumps. The space is defined as a <code>continuous box</code> of <code>[[0,0],[10,10]]</code>.</p>"},{"location":"env/four_tank/#reward","title":"Reward","text":"<p>The reward is a continuous value corresponding to square error of the state and its setpoint. For multiple states, these are scaled with a factor <code>r_scale</code> and summed to give a single value. The goal of this environment is to drive the $x_1$ state to the origin.</p>"},{"location":"env/four_tank/#reference","title":"Reference","text":"<p>The original model was created by Johansson et. al. (2000).</p>"},{"location":"env/nonsmooth_control/","title":"Nonsmooth Control","text":""},{"location":"env/nonsmooth_control/#description-equations","title":"Description &amp; Equations","text":"<p>The environment used in the this problem is a second-order system with distinct poles defined by the the following:</p> <p>\\begin{align} \\nonumber\\dfrac{d}{dt} \\begin{pmatrix} x_1 \\\\ x_2 \\ \\end{pmatrix} =  \\begin{bmatrix} 0 &amp; 1 \\\\ -2 &amp; -3 \\end{bmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\ \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 1 \\ \\end{pmatrix} u  \\end{align}</p> <p>where $x$ is the state variable and $u$ is the action variable.</p>"},{"location":"env/nonsmooth_control/#observation","title":"Observation","text":"<p>The observation of the <code>Nonsmooth Control</code> environment provides information on the state variables and their associated setpoints (if they exist) at the current timestep. The observation is an array of shape <code>(1, 2)</code>. Therefore, the observation is <code>[x_1, x_sp]</code>.</p>"},{"location":"env/nonsmooth_control/#action","title":"Action","text":"<p>The action space is a <code>ContinuousBox</code> of <code>[-1,1]</code>.</p>"},{"location":"env/nonsmooth_control/#reward","title":"Reward","text":"<p>The reward is a continuous value corresponding to square error of the state and its setpoint. For multiple states, these are scaled with a factor <code>r_scale</code> and summed to give a single value. The goal of this environment is to drive the $x_1$ state to the origin.</p>"},{"location":"env/nonsmooth_control/#reference","title":"Reference","text":"<p>The original model was created by Lim (1969).</p>"},{"location":"env/photoproduction/","title":"Photoproduction","text":""},{"location":"env/photoproduction/#photo-production-of-phycocyanin","title":"Photo Production of Phycocyanin","text":""},{"location":"env/photoproduction/#description-equations","title":"Description &amp; Equations","text":"<p>A model describing the photo production of phycocyanin from Cyanobacteria Arthrospira platensis. The system is described by three state variables representing biomass concentration ($c_x$), nitrate concentration ($c_N$), and phycocyanin concentration ($c_q$).</p> <p>The system dynamics are governed by the following equations:</p> <p>$$ \\frac{dc_x}{dt} = \\frac{\\mu_m I}{I + k_s + \\frac{I^2}{k_i}} \\cdot \\frac{c_x c_N}{c_N + k_N} - \\mu_d c_x $$</p> <p>$$ \\frac{dc_N}{dt} = -Y_{NX} \\frac{\\mu_m I}{I + k_s + \\frac{I^2}{k_i}} \\cdot \\frac{c_x c_N}{c_N + k_N} + F_N $$</p> <p>$$ \\frac{dc_q}{dt} = \\frac{k_m I}{I + k_{sq} + \\frac{I^2}{k_{iq}}} c_x - \\frac{k_d c_q}{c_N + K_{Nq}} $$</p> <p>where $\\mathbf{x} = [c_x, c_N, c_q]^\\intercal \\in \\mathbb{R}^3$ represents the state vector and $\\mathbf{u} = [I, F_N]^\\intercal$ represents the input vector consisting of light intensity ($I$) and nitrate feed rate ($F_N$).</p>"},{"location":"env/photoproduction/#initial-conditions","title":"Initial Conditions","text":"<p>The initial conditions for the state variables are defined as follows: - $\\mathbf{x_0} = [0.1, 20.0, 0.01]$: Initial state vector representing the initial concentrations of biomass, nitrate, and phycocyanin, respectively.</p>"},{"location":"env/photoproduction/#model-parameters","title":"Model Parameters","text":"<p>The model includes the following parameters: - $\\mu_m = 0.0572$: Maximum specific growth rate - $\\mu_d = 0.0$: Death rate - $Y_{NX} = 504.5$: Yield coefficient - $k_m = 0.00016$: Product formation rate - $k_d = 0.281$: Product degradation rate - $k_{sq} = 23.51$: Light saturation constant for product formation - $K_{Nq} = 16.89$: Nitrate saturation constant for product degradation - $k_{iq} = 800.0$: Light inhibition constant for product formation</p>"},{"location":"env/photoproduction/#states","title":"States","text":"<p>The model has three states: - $c_x$: Biomass concentration - $c_N$: Nitrate concentration - $c_q$: Phycocyanin concentration</p>"},{"location":"env/photoproduction/#inputs","title":"Inputs","text":"<p>The system has two control inputs: - $I$: Light intensity - $F_N$: Nitrate feed rate</p>"},{"location":"env/photoproduction/#reference","title":"Reference","text":"<p>This model implementation and its description were kindly provided by Mathew Marsh. The original model was created by Bradford et. al. (2020). </p>"},{"location":"guides/Policy%20Evaluation/","title":"Policy Evaluation","text":"<p>This is a user guide for the policy evaluation tool in pc-gym which will walkthrough an example of how to use the policy evaluation tools available in <code>pc-gym</code></p>"},{"location":"guides/Policy%20Evaluation/#plot-rollout","title":"Plot Rollout","text":"<p>The following code shows the policy and oracle comparison capability. The oracle is defined as a NMPC with perfect model (oracle uses ocp with control cost which differs from the reward function used by the RL agent) and can be sensitive to tuning of the horizon and control cost. </p> <pre><code>policies = {'PPO': PPO_policy,'SAC':SAC_policy} # Dictionary of policies to compare\nevaluator,data = env.plot_rollout(policies, reps = 10, oracle=True, dist_reward=True, MPC_params={'N':15,'R':5})\n</code></pre>"},{"location":"guides/Policy%20Evaluation/#reward-distribution-and-reproducibility-metric","title":"Reward Distribution and Reproducibility Metric","text":"<p>A visualisation of the reward distribution can also be shown using <code>dist_reward</code>.</p> <p>The <code>pc-gym</code> can also calculate dispersion and performance metrics of the distribution of rewards to allow the user to evaluate their policy. This anaylsis follows the evaluation metric used by Manon Flageat et al (2024). First an instance of the <code>reproducibility_metric</code> class is created with the user-selected metrics for both performance and dispersion: <pre><code>policy_measure = reproducibility_metric(dispersion='mad', performance='mean', scalarised_weight=2e3)\n</code></pre> Then the <code>policy_dispersion_metric</code> method can be called to return a dictionary of the dispersion metrics: <pre><code>policy_measure.policy_dispersion_metric(data, component='r')\n# which returns:\n#{'oracle': {'r': array([0.38975316])},\n# 'PPO': {'r': array([1.18513328])},\n# 'SAC': {'r': array([0.83717672])}}\n</code></pre> Then the <code>policy_performance_metric</code> and po method can be called to return a dictionary of the performance metrics: <pre><code>policy_measure.policy_performance_metric(data, component='r')\n# which returns:\n#{'oracle': {'r': array([-14.58502467])},\n# 'PPO': {'r': array([-23.76918418])},\n# 'SAC': {'r': array([-14.33262298])}}\n</code></pre></p>"},{"location":"guides/constraints/","title":"Constraints","text":""},{"location":"guides/constraints/#adding-constraints-in-pc-gym","title":"Adding Constraints in PC-Gym","text":"<p>This guide explains how to add and work with constraints in the PC-Gym environment using a practical example.</p>"},{"location":"guides/constraints/#understanding-constraints","title":"Understanding Constraints","text":"<p>In PC-Gym, constraints are used to enforce limits on system states. For example, we may want to ensure a temperature stays within certain bounds during operation.</p> <p>Constraints are defined using two key components: - A dictionary mapping states to their constraint values  - A dictionary specifying the types of constraints (e.g. greater than, less than)</p>"},{"location":"guides/constraints/#step-by-step-implementation","title":"Step-by-Step Implementation","text":""},{"location":"guides/constraints/#1-define-the-constraints","title":"1. Define the Constraints","text":"<p>First, we define constraints on the temperature T to stay between 319K and 331K. In pc-gym, we use a lambda function to define constraints and always define constraints as $$g(x,u) \\leq 0$$.</p> <pre><code>cons = lambda x, u: np.array([319 - x[1], x[1] - 331]).reshape(-1,)\n</code></pre>"},{"location":"guides/constraints/#2-configure-environment-parameters","title":"2. Configure Environment Parameters","text":"<p>Next, we update the environment parameters with the constraint settings:</p> <pre><code>env_params = {\n    # ... other parameters ...\n    'done_on_cons_vio': False,  # Episode continues even if constraint violated\n    'constraints': cons,        # Our defined constraints\n    'r_penalty': True          # Add reward penalty for constraint violations\n}\n\n# Create environment with constraints\nenv = make_env(env_params)\n</code></pre> <p>The key parameters are: - <code>done_on_cons_vio</code>: Controls whether episodes end when constraints are violated - <code>constraints</code>: The constraint function we defined - <code>r_penalty</code>: Enables reward penalties for constraint violations </p>"},{"location":"guides/constraints/#3-training-with-constraints","title":"3. Training with Constraints","text":"<p>We can now train a policy that respects these constraints using reinforcement learning. Here's an example using PPO:</p> <pre><code># Train constrained policy\nPPO_policy = PPO('MlpPolicy', env, verbose=1, learning_rate=0.001).learn(nsteps_learning)\n\n# Visualize results\nevaluator, data = env.plot_rollout({'PPO': PPO_policy}, reps=10, cons_viol=False)\n</code></pre>"},{"location":"guides/constraints/#training-with-a-constraint-example","title":"Training with a Constraint Example","text":"<p>A policy is now trained on the environment with a constraint. We use the  Proximal Policy Optimization (PPO) algorithm implemented by Stable Baselines 3. We can now rollout and plot the policy. Note the constraints on the temperature plot. The <code>cons_viol</code> input can be used to display the constraint violations. Try reducing the number of timesteps used to train the policy or tightening the constraints and turning on the constraint violation visulisation! <pre><code>constraint_policy = PPO('MlpPolicy', env, verbose=1,learning_rate=0.01).learn(total_timesteps=3e4)\nevaluator, data = env.plot_rollout(constraint_policy, reps = 10, cons_viol = False)   \n</code></pre></p>"},{"location":"guides/disturbances/","title":"Disturbances","text":"<p>This is a user guide for the disturbance function in the pc-gym which will walkthrough how to add a custom disturbance to the environment.</p>"},{"location":"guides/disturbances/#disturbance-definition","title":"Disturbance Definition","text":"<p>In this example we have already set up an environment according to the <code>Training</code> user guide. Hence we will update the environment definition with an additional disturbance input to the inlet temperature. This disturbances are defined in a dictionary named <code>disturbance</code>. The keys in the dictionary represent the state, and the values are numpy arrays that represent the disturbance for each step in the state. </p> <p>The disturbances are added to the RL state which requires a space definition hence the disturbance bounds are added to the environment definition. </p> <pre><code># Define disturbance dictionary\ndisturbance = {'Ti': np.repeat([350, 45, 350], [nsteps//4, nsteps//2, nsteps//4])}\ndisturbance_space ={\n  'low': np.array([320]),\n  'high': np.array([350])\n}\nenv = make_env({**env_params,'disturbance_bounds':disturbance_space, 'disturbances': disturbance})\n</code></pre>"},{"location":"guides/disturbances/#training-with-a-disturbance-example","title":"Training with a Disturbance Example","text":"<p>A policy is now trained on the environment with a disturbance. We use the  Proximal Policy Optimization (PPO) algorithm implemented by Stable Baselines 3. <pre><code>disturbance_policy = PPO('MlpPolicy', env, verbose=1,learning_rate=0.01).learn(total_timesteps=3e4)\nenv.plot_rollout(disturbance_policy,10)   \n</code></pre></p>"},{"location":"guides/models/","title":"Models","text":"<p>This is a user guide for the custom model function in pc-gym which will walkthrough an example of how to add a constraint to an environment.</p>"},{"location":"guides/training/","title":"Training","text":"<p>This is a user guide to setup a training algorithm using the pc-gym environment. We use  Stable Baselines 3 to implement the reinforcement learning algorithm   Proximal Policy Optimization (PPO).</p>"},{"location":"guides/training/#environment-definition","title":"Environment Definition","text":"<p>Firstly import the pc-gym library, numpy and stable baselines 3.</p> <p><pre><code>from pcgym import make_env\nimport numpy as np \nfrom stable_baselines3 import PPO\n</code></pre> In control systems, a setpoint is the target or goal for a system's output. It's the value that the control system aims to achieve.</p> <p>In this code snippet, a dictionary named <code>SP</code> is created to store the setpoints for each state. The keys in the dictionary represent the state (concentration of species A), and the values are lists that represent the setpoints for each step in the state. <pre><code>T = 26\nnsteps = 100\n# Enter required setpoints for each state.\nSP = {\n    'Ca': [0.85 for i in range(int(nsteps/2))] + [0.9 for i in range(int(nsteps/2))],\n}\n</code></pre> In reinforcement learning, the <code>action_space</code> and <code>observation_space</code> are two important concepts that define the range of possible actions that an agent can take and the range of possible observations that an agent can perceive, respectively.</p> <p>In this code snippet, both the <code>action_space</code> and <code>observation_space</code> are defined as continuous spaces, represented by a dictionary with 'low' and 'high' keys.  <pre><code># Continuous box action space\naction_space = {\n    'low': np.array([295]),\n    'high':np.array([302]) \n}\n\n# Continuous box observation space\nobservation_space = {\n    'low' : np.array([0.7,300,0.8]),\n    'high' : np.array([1,350,0.9])  \n}\n</code></pre></p> <p>In this code snippet, a dictionary named <code>env_params</code> is created to store the parameters of the environment. An instance of the <code>Models_env</code> OpenAI gym class is created with the parameters defined in the <code>env_params</code> dictionary.</p> <pre><code>r_scale ={\n    'Ca': 1e3 #Reward scale for each state\n}\nenv_params = {\n    'N': nsteps, # Number of time steps\n    'tsim':T, # Simulation Time\n    'SP':SP, # Setpoint\n    'o_space' : observation_space, # Observation space\n    'a_space' : action_space, # Action space\n    'x0': np.array([0.8,330,0.8]), # Initial conditions \n    'model': 'cstr_ode', # Select the model\n    'r_scale': r_scale, # Scale the L1 norm used for reward (|x-x_sp|*r_scale)\n    'normalise_a': True, # Normalise the actions\n    'normalise_o':True, # Normalise the states,\n    'noise':True, # Add noise to the states\n    'integration_method': 'casadi', # Select the integration method\n    'noise_percentage':0.001 # Noise percentage\n}\nenv = make_env(env_params)\n</code></pre>"},{"location":"guides/training/#policy-training","title":"Policy Training","text":"<p>Next the policy can be trained using the previously defined environment and the PPO algorithm from stable baselines 3. <pre><code>nsteps_learning = 3e4\nPPO_policy = PPO('MlpPolicy', env, verbose=1,learning_rate=0.001).learn(nsteps_learning)\n</code></pre></p>"},{"location":"guides/training/#policy-rollout-and-plotting","title":"Policy Rollout and Plotting","text":"<p>With the trained policy, the <code>plot_rollout</code> method can be called to rollout and plot the resulting state and control values. The method returns an instance of the evaluator class and the data used for the plots</p> <pre><code>evaluator, data = env.plot_rollout({'PPO': PPO_policy}, reps = 10)\n</code></pre>"}]}