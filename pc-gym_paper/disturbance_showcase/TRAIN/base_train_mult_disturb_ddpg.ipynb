{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-BcG1g4QbE_"
      },
      "source": [
        "# Cloning the Repository (pc-gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxWOGAsaECz2",
        "outputId": "899c63bc-c202-4dbc-eb5e-9de200616a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive C is Windows \n",
            " Volume Serial Number is F0B8-32A3\n",
            "\n",
            " Directory of c:\\Users\\Usuario\\Desktop\\imperial_projects\\VSCode\\pcgym2\\train\\base\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "File Not Found\n"
          ]
        }
      ],
      "source": [
        "!dir pc-gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVv4nhKnJZyQ",
        "outputId": "0c6c2f7d-37db-4485-a590-41299d74c51c"
      },
      "outputs": [],
      "source": [
        "# %cd pc-gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pXeY_oDVTPZ"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhR6YfBEbVRM",
        "outputId": "a67140ae-cfff-4a16-fbd8-dc7974929319"
      },
      "outputs": [],
      "source": [
        "# %cd src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %cd pcgym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Usuario\\Desktop\\imperial_projects\\VSCode\\pcgym2\\pc-gym\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\Desktop\\imperial_projects\\VSCode\\pcgym2\\new_venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd C:/Users/Usuario/Desktop/imperial_projects/VSCode/pcgym2/pc-gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0xr48fylffH",
        "outputId": "504b6be1-dc60-4c93-f087-158249487b25"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import gymnasium as gym\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "from stable_baselines3 import PPO,SAC,DDPG,TD3\n",
        "import pcgym\n",
        "from pcgym import make_env\n",
        "import jax.numpy as jnp\n",
        "#Global params\n",
        "T = 26\n",
        "nsteps =60\n",
        "# Global seed for reproducibility\n",
        "seed = 1990"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMPAn1SRd32f"
      },
      "source": [
        "# Saving and loading\n",
        "\n",
        "Saving and loading stable-baselines models is straightforward: you can directly call `.save()` and `.load()` on the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mph7ddv8iCjY",
        "outputId": "fc007c61-f2cd-4545-d8ee-15f900a0eb6c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Create save dir\n",
        "save_dir = \"./max/ddpg\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPlCXGwWFPTI"
      },
      "source": [
        "# Monitoring experiments with W&B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8sM9B5fOG_w",
        "outputId": "6c14e127-7339-4421-9a3b-f4c37cd16d6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Usuario\\.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login 84af17cc9914cf1736f3a8e2733a2f361e4750bb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sWhTer-Wg7X"
      },
      "source": [
        "# 1.1 Reactor Case Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZklHwMtzkOAE",
        "outputId": "209ef879-e2cb-48ac-ce44-0c2300707462"
      },
      "outputs": [],
      "source": [
        "# @title Function to log the performance data\n",
        "def log_performance(performance, test_label, file_path):\n",
        "    with open(file_path, \"a\") as file:\n",
        "        file.write(f\"{test_label}: \\n\")\n",
        "        file.write(f\"scalarised_performance: {performance}\\n\\n\")\n",
        "\n",
        "file_path = f\"{save_dir}/lcb_metric_safe.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OtCnIncfray"
      },
      "source": [
        "### RL training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch as th\n",
        "from torch import nn  # Import torch.nn for activation functions\n",
        "\n",
        "# Learning rate decay schedule\n",
        "def cosine_annealing_schedule(progress_remaining: float, num_cycles=1, min_lr=0.005, max_lr=0.01):\n",
        "    progress = 1.0 - progress_remaining\n",
        "    lr = min_lr + (max_lr - min_lr) / 2 * (1 + np.cos(np.pi * num_cycles * progress))\n",
        "    return lr\n",
        "\n",
        "# Configuration for reinforcement learning model\n",
        "config = {\n",
        "    \"policy\": 'MlpPolicy',  # default: MlpPolicy\n",
        "    \"seed\": 1990,\n",
        "    \"check_freq\": 100,  # base: 12000 (~100 episodes)\n",
        "    \"n_eval_episodes\": 10,  # evaluate the agent over 100 episodes in the evaluation environment\n",
        "    \"positive_definiteness_penalty_weight\": 0,  # Set to 0 initially\n",
        "    \"derivative_penalty_weight\": 0,  # Set to 0 initially\n",
        "    'use_direct_penalty': False,  # choose between applying a penalty directly to the critic loss or adjusting the Q target values (derivative penalty)\n",
        "    'allowed_increase_factor': 1,  # max increase value for both methods (derivative penalty)\n",
        "    # 'total_timesteps': 500000,\n",
        "    # 'action_noise_sigma': 0.34670933515233754,\n",
        "}\n",
        "\n",
        "# The best hyperparameters found in previous runs\n",
        "best_params = {\n",
        "    'min_lr': 0.0005334897747162678,\n",
        "    'max_lr': 0.0003132010556972375,\n",
        "    'pi_layer_0_units': 3,\n",
        "    'pi_layer_1_units': 4,\n",
        "    'qf_layer_0_units': 3,\n",
        "    'qf_layer_1_units': 6,\n",
        "    'activation_fn': 'LeakyReLU',\n",
        "    'buffer_size': 200000,\n",
        "    'batch_size': 512,\n",
        "    'gamma': 0.9194039413768046,\n",
        "    'tau': 0.012320756403750887,\n",
        "    'learning_starts': 2082,\n",
        "    'train_freq': 1,\n",
        "    'action_noise_sigma': 0.34670933515233754,\n",
        "    'total_timesteps': 50000,\n",
        "}\n",
        "\n",
        "# Update the config dictionary with the best parameters\n",
        "config.update(best_params)\n",
        "\n",
        "# Set the activation function directly based on best_params\n",
        "if best_params['activation_fn'] == 'Tanh':\n",
        "    activation_fn = th.nn.Tanh\n",
        "elif best_params['activation_fn'] == 'ReLU':\n",
        "    activation_fn = th.nn.ReLU\n",
        "elif best_params['activation_fn'] == 'LeakyReLU':\n",
        "    activation_fn = th.nn.LeakyReLU\n",
        "else:\n",
        "    raise ValueError(\"Unsupported activation function\")\n",
        "\n",
        "# # Create policy_kwargs with the fixed network architecture and activation function from best_params\n",
        "policy_kwargs = dict(\n",
        "    activation_fn=activation_fn,  # Use the activation function directly\n",
        "    net_arch=dict(\n",
        "        pi=[2 ** best_params['pi_layer_0_units'], 2 ** best_params['pi_layer_1_units']],\n",
        "        qf=[2 ** best_params['qf_layer_0_units'], 2 ** best_params['qf_layer_1_units']]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9qGhyfYRQMZ",
        "outputId": "0ef37754-e355-49a2-9785-2604e4a68a71"
      },
      "outputs": [],
      "source": [
        "import torch as th\n",
        "import numpy as np\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "##################################################################################\n",
        "# Environment and RL Definition\n",
        "##################################################################################\n",
        "\n",
        "# Enter required setpoints for each state. Enter None for states without setpoints.\n",
        "SP = {\n",
        "    'T': [325.0 for _ in range(nsteps)],\n",
        "}\n",
        "\n",
        "# Continuous box action space\n",
        "action_space = {\n",
        "    'low': np.array([295]),\n",
        "    'high': np.array([302])\n",
        "}\n",
        "\n",
        "# Continuous box observation space ([CA, T, CA_Setpoint, T_Setpoint])\n",
        "observation_space = {\n",
        "    'low': np.array([0.0, 300, 300]),\n",
        "    'high': np.array([1, 450, 400])\n",
        "}\n",
        "\n",
        "r_scale = {\n",
        "    'T': 1e-6  # Reward scale for each state,\n",
        "}\n",
        "\n",
        "# Define disturbance bounds\n",
        "disturbance_bounds = {\n",
        "    'low': np.array([330]),\n",
        "    'high': np.array([370])\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "env_params_template = {\n",
        "    'Nx': 2,\n",
        "    'N': 60,\n",
        "    'tsim': 26,\n",
        "    'Nu': 1,\n",
        "    'SP': SP,\n",
        "    'o_space': observation_space,\n",
        "    'a_space': action_space,\n",
        "    'x0': np.array([0.87725294608097, 324.475443431599, 324.475443431599]),\n",
        "    'model': 'cstr',\n",
        "    'r_scale': r_scale,\n",
        "    'normalise_a': True,\n",
        "    'normalise_o': True,\n",
        "    'noise': True,\n",
        "    'integration_method': 'casadi',\n",
        "    'noise_percentage': 0.001,  # 0.001,\n",
        "    'disturbance_bounds': disturbance_bounds\n",
        "}\n",
        "\n",
        "# Add noise_percentage from env_params to config\n",
        "config['noise_percentage'] = env_params_template['noise_percentage']\n",
        "\n",
        "# Seed everything for reproducibility\n",
        "def set_global_seeds(seed):\n",
        "    np.random.seed(seed)\n",
        "    th.manual_seed(seed)\n",
        "    if th.cuda.is_available():\n",
        "        th.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "# Function to create random disturbances\n",
        "def create_random_disturbances(seed, nsteps, low=345, high=355):\n",
        "    # Set the global seed for reproducibility\n",
        "    set_global_seeds(seed)\n",
        "    value = np.random.uniform(low, high, 1)[0]  # Generate a single random disturbance value within the specified range\n",
        "    disturbances = {'Ti': [350] * (nsteps // 3) + [value] * (nsteps // 3) + [350] * (nsteps // 3)}  # Repeat each disturbance value for nsteps/3 times\n",
        "    return disturbances\n",
        "\n",
        "# Create multiple environments with different disturbances\n",
        "def create_parallel_envs(n_envs, seed):\n",
        "    set_global_seeds(seed)\n",
        "    envs = []\n",
        "    disturbances_list = []\n",
        "    for i in range(n_envs):\n",
        "        env_params = env_params_template.copy()\n",
        "        disturbances = create_random_disturbances(seed + i, nsteps)\n",
        "        env_params.update({'disturbances': disturbances})\n",
        "        disturbances_list.append(disturbances)\n",
        "        envs.append(lambda: make_env(env_params))\n",
        "    return DummyVecEnv(envs), disturbances_list\n",
        "\n",
        "# Create evaluation environment using DummyVecEnv\n",
        "def create_eval_env(seed, n_envs=1):\n",
        "    set_global_seeds(seed)\n",
        "    envs = []\n",
        "    for i in range(n_envs):\n",
        "        env_params = env_params_template.copy()\n",
        "        disturbances = create_random_disturbances(seed + i, nsteps)\n",
        "        env_params.update({'disturbances': disturbances})\n",
        "        envs.append(lambda: make_env(env_params))\n",
        "    return DummyVecEnv(envs)\n",
        "\n",
        "eval_env = create_eval_env(seed=config['seed'], n_envs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "29c77ed8695a4287956ec27672fe7b7a",
            "5b907d9cb030400c8cd9308246d761c1",
            "bf4a59f3065346d6af96d1fc1a2e6385",
            "c341e0ddb94f4c0b9066e8dc99136430",
            "ac046599192d45cfbf5ab150f9fb240d",
            "483c79836eed4cfab4cfc7320151ef66",
            "e8afd67546254f249e488008aa76f0a8",
            "6446e95478cf4113aad04353ba1c2030"
          ]
        },
        "id": "ZhPjWJ7AfjMs",
        "outputId": "eef1f821-6644-4a6c-9131-889a6f18b697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First disturbance used in training: {'Ti': [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 352.21977257492216, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350]}\n",
            "Using cpu device\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 564      |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 590      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0339   |\n",
            "|    critic_loss     | 1.34e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 48       |\n",
            "---------------------------------\n",
            "----------------------------\n",
            "| time/              |     |\n",
            "|    episodes        | 8   |\n",
            "|    fps             | 563 |\n",
            "|    time_elapsed    | 1   |\n",
            "|    total_timesteps | 590 |\n",
            "----------------------------\n",
            "Eval num_timesteps=1000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -5.99e-05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1000      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0325    |\n",
            "|    critic_loss     | 5.34e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 89        |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 395      |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 1180     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0314   |\n",
            "|    critic_loss     | 1.61e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 107      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 16   |\n",
            "|    fps             | 395  |\n",
            "|    time_elapsed    | 2    |\n",
            "|    total_timesteps | 1180 |\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 20   |\n",
            "|    fps             | 395  |\n",
            "|    time_elapsed    | 2    |\n",
            "|    total_timesteps | 1180 |\n",
            "-----------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 419      |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 1770     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.029    |\n",
            "|    critic_loss     | 1.88e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 166      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 28   |\n",
            "|    fps             | 419  |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 1770 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=2000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -9.27e-05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2000      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0309    |\n",
            "|    critic_loss     | 8.15e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 189       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 373      |\n",
            "|    time_elapsed    | 6        |\n",
            "|    total_timesteps | 2360     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0303   |\n",
            "|    critic_loss     | 4.28e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 225      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 36   |\n",
            "|    fps             | 373  |\n",
            "|    time_elapsed    | 6    |\n",
            "|    total_timesteps | 2360 |\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 40   |\n",
            "|    fps             | 373  |\n",
            "|    time_elapsed    | 6    |\n",
            "|    total_timesteps | 2360 |\n",
            "-----------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 384      |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total_timesteps | 2950     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0291   |\n",
            "|    critic_loss     | 9.16e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 284      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 48   |\n",
            "|    fps             | 384  |\n",
            "|    time_elapsed    | 7    |\n",
            "|    total_timesteps | 2950 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=3000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 59       |\n",
            "|    mean_reward     | -9e-05   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 3000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0278   |\n",
            "|    critic_loss     | 8.41e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 289      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 364      |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 3540     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0313   |\n",
            "|    critic_loss     | 3.99e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 343      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 56   |\n",
            "|    fps             | 364  |\n",
            "|    time_elapsed    | 9    |\n",
            "|    total_timesteps | 3540 |\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 60   |\n",
            "|    fps             | 364  |\n",
            "|    time_elapsed    | 9    |\n",
            "|    total_timesteps | 3540 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=4000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000103 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 4000      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0283    |\n",
            "|    critic_loss     | 1.4e-05   |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 389       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 352      |\n",
            "|    time_elapsed    | 11       |\n",
            "|    total_timesteps | 4130     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0277   |\n",
            "|    critic_loss     | 1.59e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 402      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 68   |\n",
            "|    fps             | 352  |\n",
            "|    time_elapsed    | 11   |\n",
            "|    total_timesteps | 4130 |\n",
            "-----------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 361      |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 4720     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0267   |\n",
            "|    critic_loss     | 9.54e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 461      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 76   |\n",
            "|    fps             | 361  |\n",
            "|    time_elapsed    | 13   |\n",
            "|    total_timesteps | 4720 |\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 80   |\n",
            "|    fps             | 361  |\n",
            "|    time_elapsed    | 13   |\n",
            "|    total_timesteps | 4720 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=5000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000127 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 5000      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0255    |\n",
            "|    critic_loss     | 1.24e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 489       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 350      |\n",
            "|    time_elapsed    | 15       |\n",
            "|    total_timesteps | 5310     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0294   |\n",
            "|    critic_loss     | 1.19e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 520      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 88   |\n",
            "|    fps             | 350  |\n",
            "|    time_elapsed    | 15   |\n",
            "|    total_timesteps | 5310 |\n",
            "-----------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 355      |\n",
            "|    time_elapsed    | 16       |\n",
            "|    total_timesteps | 5900     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0251   |\n",
            "|    critic_loss     | 7.8e-06  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 579      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 96   |\n",
            "|    fps             | 355  |\n",
            "|    time_elapsed    | 16   |\n",
            "|    total_timesteps | 5900 |\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 100  |\n",
            "|    fps             | 355  |\n",
            "|    time_elapsed    | 16   |\n",
            "|    total_timesteps | 5900 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=6000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000124 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 6000      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0261    |\n",
            "|    critic_loss     | 2.22e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 589       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 345      |\n",
            "|    time_elapsed    | 18       |\n",
            "|    total_timesteps | 6490     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0279   |\n",
            "|    critic_loss     | 1.16e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 638      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 108  |\n",
            "|    fps             | 345  |\n",
            "|    time_elapsed    | 18   |\n",
            "|    total_timesteps | 6490 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=7000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000122 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 7000      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0251    |\n",
            "|    critic_loss     | 2.46e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 689       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 337      |\n",
            "|    time_elapsed    | 20       |\n",
            "|    total_timesteps | 7080     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0255   |\n",
            "|    critic_loss     | 1.37e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 697      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 116  |\n",
            "|    fps             | 337  |\n",
            "|    time_elapsed    | 20   |\n",
            "|    total_timesteps | 7080 |\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 120  |\n",
            "|    fps             | 337  |\n",
            "|    time_elapsed    | 20   |\n",
            "|    total_timesteps | 7080 |\n",
            "-----------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 342      |\n",
            "|    time_elapsed    | 22       |\n",
            "|    total_timesteps | 7670     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0249   |\n",
            "|    critic_loss     | 1.31e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 756      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 128  |\n",
            "|    fps             | 342  |\n",
            "|    time_elapsed    | 22   |\n",
            "|    total_timesteps | 7670 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=8000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000111 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 8000      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0255    |\n",
            "|    critic_loss     | 1.44e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 789       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 333      |\n",
            "|    time_elapsed    | 24       |\n",
            "|    total_timesteps | 8260     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0254   |\n",
            "|    critic_loss     | 1.58e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 815      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 136  |\n",
            "|    fps             | 333  |\n",
            "|    time_elapsed    | 24   |\n",
            "|    total_timesteps | 8260 |\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 140  |\n",
            "|    fps             | 333  |\n",
            "|    time_elapsed    | 24   |\n",
            "|    total_timesteps | 8260 |\n",
            "-----------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 335      |\n",
            "|    time_elapsed    | 26       |\n",
            "|    total_timesteps | 8850     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0251   |\n",
            "|    critic_loss     | 2.5e-05  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 874      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 148  |\n",
            "|    fps             | 335  |\n",
            "|    time_elapsed    | 26   |\n",
            "|    total_timesteps | 8850 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=9000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000116 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 9000      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0259    |\n",
            "|    critic_loss     | 1.06e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 889       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 327      |\n",
            "|    time_elapsed    | 28       |\n",
            "|    total_timesteps | 9440     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0275   |\n",
            "|    critic_loss     | 5.64e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 933      |\n",
            "---------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 156  |\n",
            "|    fps             | 327  |\n",
            "|    time_elapsed    | 28   |\n",
            "|    total_timesteps | 9440 |\n",
            "-----------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    episodes        | 160  |\n",
            "|    fps             | 327  |\n",
            "|    time_elapsed    | 28   |\n",
            "|    total_timesteps | 9440 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000111 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 10000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0229    |\n",
            "|    critic_loss     | 1.46e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 989       |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 322      |\n",
            "|    time_elapsed    | 31       |\n",
            "|    total_timesteps | 10030    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0227   |\n",
            "|    critic_loss     | 1.31e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 992      |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 168   |\n",
            "|    fps             | 322   |\n",
            "|    time_elapsed    | 31    |\n",
            "|    total_timesteps | 10030 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 324      |\n",
            "|    time_elapsed    | 32       |\n",
            "|    total_timesteps | 10620    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0266   |\n",
            "|    critic_loss     | 5.46e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1051     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 176   |\n",
            "|    fps             | 324   |\n",
            "|    time_elapsed    | 32    |\n",
            "|    total_timesteps | 10620 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 180   |\n",
            "|    fps             | 324   |\n",
            "|    time_elapsed    | 32    |\n",
            "|    total_timesteps | 10620 |\n",
            "------------------------------\n",
            "Eval num_timesteps=11000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 59       |\n",
            "|    mean_reward     | -0.00011 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 11000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0239   |\n",
            "|    critic_loss     | 1.11e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1089     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 320      |\n",
            "|    time_elapsed    | 34       |\n",
            "|    total_timesteps | 11210    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0251   |\n",
            "|    critic_loss     | 7.08e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1110     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 188   |\n",
            "|    fps             | 320   |\n",
            "|    time_elapsed    | 34    |\n",
            "|    total_timesteps | 11210 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 322      |\n",
            "|    time_elapsed    | 36       |\n",
            "|    total_timesteps | 11800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0248   |\n",
            "|    critic_loss     | 1.11e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1169     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 196   |\n",
            "|    fps             | 322   |\n",
            "|    time_elapsed    | 36    |\n",
            "|    total_timesteps | 11800 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 200   |\n",
            "|    fps             | 322   |\n",
            "|    time_elapsed    | 36    |\n",
            "|    total_timesteps | 11800 |\n",
            "------------------------------\n",
            "Eval num_timesteps=12000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 59       |\n",
            "|    mean_reward     | -0.00011 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 12000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0279   |\n",
            "|    critic_loss     | 8.43e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1189     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 204      |\n",
            "|    fps             | 318      |\n",
            "|    time_elapsed    | 38       |\n",
            "|    total_timesteps | 12390    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0238   |\n",
            "|    critic_loss     | 8.89e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1228     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 208   |\n",
            "|    fps             | 318   |\n",
            "|    time_elapsed    | 38    |\n",
            "|    total_timesteps | 12390 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 212      |\n",
            "|    fps             | 320      |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 12980    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0235   |\n",
            "|    critic_loss     | 1.16e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1287     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 216   |\n",
            "|    fps             | 320   |\n",
            "|    time_elapsed    | 40    |\n",
            "|    total_timesteps | 12980 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 220   |\n",
            "|    fps             | 320   |\n",
            "|    time_elapsed    | 40    |\n",
            "|    total_timesteps | 12980 |\n",
            "------------------------------\n",
            "Eval num_timesteps=13000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000116 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 13000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0244    |\n",
            "|    critic_loss     | 1.11e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 1289      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 224      |\n",
            "|    fps             | 315      |\n",
            "|    time_elapsed    | 43       |\n",
            "|    total_timesteps | 13570    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0231   |\n",
            "|    critic_loss     | 1.02e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1346     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 228   |\n",
            "|    fps             | 315   |\n",
            "|    time_elapsed    | 43    |\n",
            "|    total_timesteps | 13570 |\n",
            "------------------------------\n",
            "Eval num_timesteps=14000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000108 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 14000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0228    |\n",
            "|    critic_loss     | 9.15e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 1389      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 232      |\n",
            "|    fps             | 311      |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 14160    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0222   |\n",
            "|    critic_loss     | 9.87e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1405     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 236   |\n",
            "|    fps             | 311   |\n",
            "|    time_elapsed    | 45    |\n",
            "|    total_timesteps | 14160 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 240   |\n",
            "|    fps             | 311   |\n",
            "|    time_elapsed    | 45    |\n",
            "|    total_timesteps | 14160 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 244      |\n",
            "|    fps             | 313      |\n",
            "|    time_elapsed    | 47       |\n",
            "|    total_timesteps | 14750    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0225   |\n",
            "|    critic_loss     | 1.19e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1464     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 248   |\n",
            "|    fps             | 313   |\n",
            "|    time_elapsed    | 47    |\n",
            "|    total_timesteps | 14750 |\n",
            "------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000119 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 15000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0231    |\n",
            "|    critic_loss     | 1.01e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 1489      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 252      |\n",
            "|    fps             | 310      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 15340    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0228   |\n",
            "|    critic_loss     | 1.52e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1523     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 256   |\n",
            "|    fps             | 310   |\n",
            "|    time_elapsed    | 49    |\n",
            "|    total_timesteps | 15340 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 260   |\n",
            "|    fps             | 310   |\n",
            "|    time_elapsed    | 49    |\n",
            "|    total_timesteps | 15340 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 264      |\n",
            "|    fps             | 312      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 15930    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0234   |\n",
            "|    critic_loss     | 7.8e-06  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1582     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 268   |\n",
            "|    fps             | 312   |\n",
            "|    time_elapsed    | 51    |\n",
            "|    total_timesteps | 15930 |\n",
            "------------------------------\n",
            "Eval num_timesteps=16000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000112 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 16000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0221    |\n",
            "|    critic_loss     | 8.75e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 1589      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 272      |\n",
            "|    fps             | 308      |\n",
            "|    time_elapsed    | 53       |\n",
            "|    total_timesteps | 16520    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0241   |\n",
            "|    critic_loss     | 8.63e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1641     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 276   |\n",
            "|    fps             | 308   |\n",
            "|    time_elapsed    | 53    |\n",
            "|    total_timesteps | 16520 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 280   |\n",
            "|    fps             | 308   |\n",
            "|    time_elapsed    | 53    |\n",
            "|    total_timesteps | 16520 |\n",
            "------------------------------\n",
            "Eval num_timesteps=17000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000111 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 17000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0203    |\n",
            "|    critic_loss     | 8.34e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 1689      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 284      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 55       |\n",
            "|    total_timesteps | 17110    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0226   |\n",
            "|    critic_loss     | 1.07e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1700     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 288   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 55    |\n",
            "|    total_timesteps | 17110 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 292      |\n",
            "|    fps             | 308      |\n",
            "|    time_elapsed    | 57       |\n",
            "|    total_timesteps | 17700    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0227   |\n",
            "|    critic_loss     | 9.14e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1759     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 296   |\n",
            "|    fps             | 308   |\n",
            "|    time_elapsed    | 57    |\n",
            "|    total_timesteps | 17700 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 300   |\n",
            "|    fps             | 308   |\n",
            "|    time_elapsed    | 57    |\n",
            "|    total_timesteps | 17700 |\n",
            "------------------------------\n",
            "Eval num_timesteps=18000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000109 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 18000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0216    |\n",
            "|    critic_loss     | 6.73e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 1789      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 304      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 59       |\n",
            "|    total_timesteps | 18290    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0204   |\n",
            "|    critic_loss     | 1.13e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1818     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 308   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 59    |\n",
            "|    total_timesteps | 18290 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 312      |\n",
            "|    fps             | 309      |\n",
            "|    time_elapsed    | 61       |\n",
            "|    total_timesteps | 18880    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0216   |\n",
            "|    critic_loss     | 5.07e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1877     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 316   |\n",
            "|    fps             | 309   |\n",
            "|    time_elapsed    | 61    |\n",
            "|    total_timesteps | 18880 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 320   |\n",
            "|    fps             | 309   |\n",
            "|    time_elapsed    | 61    |\n",
            "|    total_timesteps | 18880 |\n",
            "------------------------------\n",
            "Eval num_timesteps=19000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000103 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 19000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0236    |\n",
            "|    critic_loss     | 3.11e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 1889      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 324      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 63       |\n",
            "|    total_timesteps | 19470    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0225   |\n",
            "|    critic_loss     | 7.91e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1936     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 328   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 63    |\n",
            "|    total_timesteps | 19470 |\n",
            "------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 59       |\n",
            "|    mean_reward     | -0.0001  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0213   |\n",
            "|    critic_loss     | 1.28e-05 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1989     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 332      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 65       |\n",
            "|    total_timesteps | 20060    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0214   |\n",
            "|    critic_loss     | 8.45e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 1995     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 336   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 65    |\n",
            "|    total_timesteps | 20060 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 340   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 65    |\n",
            "|    total_timesteps | 20060 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 344      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 67       |\n",
            "|    total_timesteps | 20650    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0216   |\n",
            "|    critic_loss     | 3.63e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2054     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 348   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 67    |\n",
            "|    total_timesteps | 20650 |\n",
            "------------------------------\n",
            "Eval num_timesteps=21000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000112 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 21000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0209    |\n",
            "|    critic_loss     | 7.28e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2089      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 352      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 69       |\n",
            "|    total_timesteps | 21240    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0206   |\n",
            "|    critic_loss     | 8.24e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2113     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 356   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 69    |\n",
            "|    total_timesteps | 21240 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 360   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 69    |\n",
            "|    total_timesteps | 21240 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 364      |\n",
            "|    fps             | 308      |\n",
            "|    time_elapsed    | 70       |\n",
            "|    total_timesteps | 21830    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0195   |\n",
            "|    critic_loss     | 1.3e-05  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2172     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 368   |\n",
            "|    fps             | 308   |\n",
            "|    time_elapsed    | 70    |\n",
            "|    total_timesteps | 21830 |\n",
            "------------------------------\n",
            "Eval num_timesteps=22000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000104 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 22000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0221    |\n",
            "|    critic_loss     | 8.42e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2189      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 372      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 22420    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0202   |\n",
            "|    critic_loss     | 6.97e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2231     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 376   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 73    |\n",
            "|    total_timesteps | 22420 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 380   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 73    |\n",
            "|    total_timesteps | 22420 |\n",
            "------------------------------\n",
            "Eval num_timesteps=23000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000107 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 23000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.019     |\n",
            "|    critic_loss     | 8.42e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2289      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 384      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 75       |\n",
            "|    total_timesteps | 23010    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.022    |\n",
            "|    critic_loss     | 4e-06    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2290     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 388   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 75    |\n",
            "|    total_timesteps | 23010 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 392      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 76       |\n",
            "|    total_timesteps | 23600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0214   |\n",
            "|    critic_loss     | 9.73e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2349     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 396   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 76    |\n",
            "|    total_timesteps | 23600 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 400   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 76    |\n",
            "|    total_timesteps | 23600 |\n",
            "------------------------------\n",
            "Eval num_timesteps=24000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000104 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 24000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0207    |\n",
            "|    critic_loss     | 3.87e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2389      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 404      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 79       |\n",
            "|    total_timesteps | 24190    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0192   |\n",
            "|    critic_loss     | 8.94e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2408     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 408   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 79    |\n",
            "|    total_timesteps | 24190 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 412      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 80       |\n",
            "|    total_timesteps | 24780    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0207   |\n",
            "|    critic_loss     | 4.45e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2467     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 416   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 80    |\n",
            "|    total_timesteps | 24780 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 420   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 80    |\n",
            "|    total_timesteps | 24780 |\n",
            "------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000102 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 25000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0205    |\n",
            "|    critic_loss     | 8.53e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2489      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 424      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 82       |\n",
            "|    total_timesteps | 25370    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0188   |\n",
            "|    critic_loss     | 6.48e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2526     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 428   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 82    |\n",
            "|    total_timesteps | 25370 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 432      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 84       |\n",
            "|    total_timesteps | 25960    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0199   |\n",
            "|    critic_loss     | 7.35e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2585     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 436   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 84    |\n",
            "|    total_timesteps | 25960 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 440   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 84    |\n",
            "|    total_timesteps | 25960 |\n",
            "------------------------------\n",
            "Eval num_timesteps=26000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000106 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 26000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0209    |\n",
            "|    critic_loss     | 6.44e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2589      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 444      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 86       |\n",
            "|    total_timesteps | 26550    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0198   |\n",
            "|    critic_loss     | 4.78e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2644     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 448   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 86    |\n",
            "|    total_timesteps | 26550 |\n",
            "------------------------------\n",
            "Eval num_timesteps=27000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000257 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 27000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0177    |\n",
            "|    critic_loss     | 3.28e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2689      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 452      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 88       |\n",
            "|    total_timesteps | 27140    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0198   |\n",
            "|    critic_loss     | 8.17e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2703     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 456   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 88    |\n",
            "|    total_timesteps | 27140 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 460   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 88    |\n",
            "|    total_timesteps | 27140 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 464      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 90       |\n",
            "|    total_timesteps | 27730    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0184   |\n",
            "|    critic_loss     | 4.02e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2762     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 468   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 90    |\n",
            "|    total_timesteps | 27730 |\n",
            "------------------------------\n",
            "Eval num_timesteps=28000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000335 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 28000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0181    |\n",
            "|    critic_loss     | 2.06e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2789      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 472      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 92       |\n",
            "|    total_timesteps | 28320    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0192   |\n",
            "|    critic_loss     | 4.27e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2821     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 476   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 92    |\n",
            "|    total_timesteps | 28320 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 480   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 92    |\n",
            "|    total_timesteps | 28320 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 484      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 93       |\n",
            "|    total_timesteps | 28910    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0198   |\n",
            "|    critic_loss     | 7.92e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2880     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 488   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 93    |\n",
            "|    total_timesteps | 28910 |\n",
            "------------------------------\n",
            "Eval num_timesteps=29000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000425 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 29000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0193    |\n",
            "|    critic_loss     | 1.04e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2889      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 492      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 96       |\n",
            "|    total_timesteps | 29500    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0191   |\n",
            "|    critic_loss     | 6.95e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2939     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 496   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 96    |\n",
            "|    total_timesteps | 29500 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 500   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 96    |\n",
            "|    total_timesteps | 29500 |\n",
            "------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000464 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 30000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0185    |\n",
            "|    critic_loss     | 1.03e-05  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 2989      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 504      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 98       |\n",
            "|    total_timesteps | 30090    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0172   |\n",
            "|    critic_loss     | 7.05e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 2998     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 508   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 98    |\n",
            "|    total_timesteps | 30090 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 512      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 99       |\n",
            "|    total_timesteps | 30680    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0191   |\n",
            "|    critic_loss     | 5.45e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3057     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 516   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 99    |\n",
            "|    total_timesteps | 30680 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 520   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 99    |\n",
            "|    total_timesteps | 30680 |\n",
            "------------------------------\n",
            "Eval num_timesteps=31000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 59       |\n",
            "|    mean_reward     | -0.00041 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 31000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0174   |\n",
            "|    critic_loss     | 2.56e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3089     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 524      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 102      |\n",
            "|    total_timesteps | 31270    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.019    |\n",
            "|    critic_loss     | 4.84e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3116     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 528   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 102   |\n",
            "|    total_timesteps | 31270 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 532      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 103      |\n",
            "|    total_timesteps | 31860    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0177   |\n",
            "|    critic_loss     | 6.84e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3175     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 536   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 103   |\n",
            "|    total_timesteps | 31860 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 540   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 103   |\n",
            "|    total_timesteps | 31860 |\n",
            "------------------------------\n",
            "Eval num_timesteps=32000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000382 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 32000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0184    |\n",
            "|    critic_loss     | 4.22e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 3189      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 544      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 105      |\n",
            "|    total_timesteps | 32450    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0188   |\n",
            "|    critic_loss     | 5.42e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3234     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 548   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 105   |\n",
            "|    total_timesteps | 32450 |\n",
            "------------------------------\n",
            "Eval num_timesteps=33000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000356 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 33000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0182    |\n",
            "|    critic_loss     | 4.67e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 3289      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 552      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 108      |\n",
            "|    total_timesteps | 33040    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0188   |\n",
            "|    critic_loss     | 2.61e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3293     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 556   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 108   |\n",
            "|    total_timesteps | 33040 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 560   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 108   |\n",
            "|    total_timesteps | 33040 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 564      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 109      |\n",
            "|    total_timesteps | 33630    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0184   |\n",
            "|    critic_loss     | 5.38e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3352     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 568   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 109   |\n",
            "|    total_timesteps | 33630 |\n",
            "------------------------------\n",
            "Eval num_timesteps=34000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000322 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 34000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0169    |\n",
            "|    critic_loss     | 3.49e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 3389      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 572      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 111      |\n",
            "|    total_timesteps | 34220    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0151   |\n",
            "|    critic_loss     | 7.18e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3411     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 576   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 111   |\n",
            "|    total_timesteps | 34220 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 580   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 111   |\n",
            "|    total_timesteps | 34220 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 584      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 113      |\n",
            "|    total_timesteps | 34810    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0171   |\n",
            "|    critic_loss     | 7.54e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3470     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 588   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 113   |\n",
            "|    total_timesteps | 34810 |\n",
            "------------------------------\n",
            "Eval num_timesteps=35000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000292 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 35000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0163    |\n",
            "|    critic_loss     | 7.11e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 3489      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 592      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 115      |\n",
            "|    total_timesteps | 35400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0168   |\n",
            "|    critic_loss     | 7.59e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3529     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 596   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 115   |\n",
            "|    total_timesteps | 35400 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 600   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 115   |\n",
            "|    total_timesteps | 35400 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 604      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 35990    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0159   |\n",
            "|    critic_loss     | 6.03e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3588     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 608   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 117   |\n",
            "|    total_timesteps | 35990 |\n",
            "------------------------------\n",
            "Eval num_timesteps=36000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000311 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 36000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0176    |\n",
            "|    critic_loss     | 4.51e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 3589      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 612      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 119      |\n",
            "|    total_timesteps | 36580    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0176   |\n",
            "|    critic_loss     | 2.6e-06  |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3647     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 616   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 119   |\n",
            "|    total_timesteps | 36580 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 620   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 119   |\n",
            "|    total_timesteps | 36580 |\n",
            "------------------------------\n",
            "Eval num_timesteps=37000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000309 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 37000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0164    |\n",
            "|    critic_loss     | 4.1e-06   |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 3689      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 624      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 121      |\n",
            "|    total_timesteps | 37170    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0161   |\n",
            "|    critic_loss     | 5.41e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3706     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 628   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 121   |\n",
            "|    total_timesteps | 37170 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 632      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total_timesteps | 37760    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0171   |\n",
            "|    critic_loss     | 9.15e-07 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3765     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 636   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 123   |\n",
            "|    total_timesteps | 37760 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 640   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 123   |\n",
            "|    total_timesteps | 37760 |\n",
            "------------------------------\n",
            "Eval num_timesteps=38000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000287 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 38000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.017     |\n",
            "|    critic_loss     | 5.36e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 3789      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 644      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 38350    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0154   |\n",
            "|    critic_loss     | 3.93e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3824     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 648   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 125   |\n",
            "|    total_timesteps | 38350 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 652      |\n",
            "|    fps             | 307      |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 38940    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0157   |\n",
            "|    critic_loss     | 3.24e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3883     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 656   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 126   |\n",
            "|    total_timesteps | 38940 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 660   |\n",
            "|    fps             | 307   |\n",
            "|    time_elapsed    | 126   |\n",
            "|    total_timesteps | 38940 |\n",
            "------------------------------\n",
            "Eval num_timesteps=39000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000228 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 39000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.016     |\n",
            "|    critic_loss     | 4.37e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 3889      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 664      |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 128      |\n",
            "|    total_timesteps | 39530    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0166   |\n",
            "|    critic_loss     | 6.76e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3942     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 668   |\n",
            "|    fps             | 306   |\n",
            "|    time_elapsed    | 128   |\n",
            "|    total_timesteps | 39530 |\n",
            "------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 59       |\n",
            "|    mean_reward     | -0.00022 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0155   |\n",
            "|    critic_loss     | 2.48e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 3989     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 672      |\n",
            "|    fps             | 304      |\n",
            "|    time_elapsed    | 131      |\n",
            "|    total_timesteps | 40120    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0159   |\n",
            "|    critic_loss     | 3e-06    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4001     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 676   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 131   |\n",
            "|    total_timesteps | 40120 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 680   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 131   |\n",
            "|    total_timesteps | 40120 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 684      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 133      |\n",
            "|    total_timesteps | 40710    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.016    |\n",
            "|    critic_loss     | 3.63e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4060     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 688   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 133   |\n",
            "|    total_timesteps | 40710 |\n",
            "------------------------------\n",
            "Eval num_timesteps=41000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000217 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 41000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0141    |\n",
            "|    critic_loss     | 2.67e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4089      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 692      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 135      |\n",
            "|    total_timesteps | 41300    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0154   |\n",
            "|    critic_loss     | 3.34e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4119     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 696   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 135   |\n",
            "|    total_timesteps | 41300 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 700   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 135   |\n",
            "|    total_timesteps | 41300 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 704      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 136      |\n",
            "|    total_timesteps | 41890    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0161   |\n",
            "|    critic_loss     | 4.24e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4178     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 708   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 136   |\n",
            "|    total_timesteps | 41890 |\n",
            "------------------------------\n",
            "Eval num_timesteps=42000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000158 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 42000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0162    |\n",
            "|    critic_loss     | 5.74e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4189      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 712      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 139      |\n",
            "|    total_timesteps | 42480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0151   |\n",
            "|    critic_loss     | 1.92e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4237     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 716   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 139   |\n",
            "|    total_timesteps | 42480 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 720   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 139   |\n",
            "|    total_timesteps | 42480 |\n",
            "------------------------------\n",
            "Eval num_timesteps=43000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000141 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 43000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0161    |\n",
            "|    critic_loss     | 8.93e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4289      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 724      |\n",
            "|    fps             | 304      |\n",
            "|    time_elapsed    | 141      |\n",
            "|    total_timesteps | 43070    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0158   |\n",
            "|    critic_loss     | 4.37e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4296     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 728   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 141   |\n",
            "|    total_timesteps | 43070 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 732      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 142      |\n",
            "|    total_timesteps | 43660    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0151   |\n",
            "|    critic_loss     | 2.22e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4355     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 736   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 142   |\n",
            "|    total_timesteps | 43660 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 740   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 142   |\n",
            "|    total_timesteps | 43660 |\n",
            "------------------------------\n",
            "Eval num_timesteps=44000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000134 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 44000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0166    |\n",
            "|    critic_loss     | 3.19e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4389      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 744      |\n",
            "|    fps             | 304      |\n",
            "|    time_elapsed    | 145      |\n",
            "|    total_timesteps | 44250    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0141   |\n",
            "|    critic_loss     | 3.85e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4414     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 748   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 145   |\n",
            "|    total_timesteps | 44250 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 752      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 146      |\n",
            "|    total_timesteps | 44840    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0162   |\n",
            "|    critic_loss     | 3.67e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4473     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 756   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 146   |\n",
            "|    total_timesteps | 44840 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 760   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 146   |\n",
            "|    total_timesteps | 44840 |\n",
            "------------------------------\n",
            "Eval num_timesteps=45000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000137 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 45000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0147    |\n",
            "|    critic_loss     | 4.21e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4489      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 764      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 148      |\n",
            "|    total_timesteps | 45430    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.015    |\n",
            "|    critic_loss     | 4.63e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4532     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 768   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 148   |\n",
            "|    total_timesteps | 45430 |\n",
            "------------------------------\n",
            "Eval num_timesteps=46000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000133 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 46000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0143    |\n",
            "|    critic_loss     | 5.37e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4589      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 772      |\n",
            "|    fps             | 304      |\n",
            "|    time_elapsed    | 151      |\n",
            "|    total_timesteps | 46020    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0153   |\n",
            "|    critic_loss     | 3.97e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4591     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 776   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 151   |\n",
            "|    total_timesteps | 46020 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 780   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 151   |\n",
            "|    total_timesteps | 46020 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 784      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 152      |\n",
            "|    total_timesteps | 46610    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0129   |\n",
            "|    critic_loss     | 5.69e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4650     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 788   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 152   |\n",
            "|    total_timesteps | 46610 |\n",
            "------------------------------\n",
            "Eval num_timesteps=47000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000125 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 47000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0117    |\n",
            "|    critic_loss     | 4.08e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4689      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 792      |\n",
            "|    fps             | 304      |\n",
            "|    time_elapsed    | 154      |\n",
            "|    total_timesteps | 47200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0158   |\n",
            "|    critic_loss     | 2.29e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4709     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 796   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 154   |\n",
            "|    total_timesteps | 47200 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 800   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 154   |\n",
            "|    total_timesteps | 47200 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 804      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 156      |\n",
            "|    total_timesteps | 47790    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0141   |\n",
            "|    critic_loss     | 3.74e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4768     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 808   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 156   |\n",
            "|    total_timesteps | 47790 |\n",
            "------------------------------\n",
            "Eval num_timesteps=48000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000135 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 48000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0132    |\n",
            "|    critic_loss     | 4.2e-06   |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4789      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 812      |\n",
            "|    fps             | 304      |\n",
            "|    time_elapsed    | 158      |\n",
            "|    total_timesteps | 48380    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0149   |\n",
            "|    critic_loss     | 1.73e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4827     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 816   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 158   |\n",
            "|    total_timesteps | 48380 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 820   |\n",
            "|    fps             | 304   |\n",
            "|    time_elapsed    | 158   |\n",
            "|    total_timesteps | 48380 |\n",
            "------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 824      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 160      |\n",
            "|    total_timesteps | 48970    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0136   |\n",
            "|    critic_loss     | 3.05e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4886     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 828   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 160   |\n",
            "|    total_timesteps | 48970 |\n",
            "------------------------------\n",
            "Eval num_timesteps=49000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000125 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 49000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0136    |\n",
            "|    critic_loss     | 3.27e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4889      |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 832      |\n",
            "|    fps             | 305      |\n",
            "|    time_elapsed    | 162      |\n",
            "|    total_timesteps | 49560    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.0136   |\n",
            "|    critic_loss     | 4.57e-06 |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 4945     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 836   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 162   |\n",
            "|    total_timesteps | 49560 |\n",
            "------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    episodes        | 840   |\n",
            "|    fps             | 305   |\n",
            "|    time_elapsed    | 162   |\n",
            "|    total_timesteps | 49560 |\n",
            "------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=-0.00 +/- 0.00\n",
            "Episode length: 59.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 59        |\n",
            "|    mean_reward     | -0.000128 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 50000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 0.0146    |\n",
            "|    critic_loss     | 3.88e-06  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 4989      |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise\n",
        "\n",
        "# Set the global seed for reproducibility\n",
        "set_global_seeds(config['seed'])\n",
        "\n",
        "# Number of parallel environments\n",
        "n_envs = 10\n",
        "\n",
        "# Create the parallel environments and get the disturbances\n",
        "env, disturbances_list = create_parallel_envs(n_envs, config['seed'])\n",
        "\n",
        "# Set up Ornstein-Uhlenbeck action noise after creating the environment\n",
        "n_actions = env.action_space.shape\n",
        "action_noise = OrnsteinUhlenbeckActionNoise(\n",
        "    mean=np.zeros(n_actions), \n",
        "    sigma=config['action_noise_sigma'] * np.ones(n_actions)\n",
        ")\n",
        "\n",
        "# Print the first disturbances\n",
        "print(\"First disturbance used in training:\", disturbances_list[0])\n",
        "\n",
        "model = DDPG(\n",
        "    config['policy'],\n",
        "    env,\n",
        "    learning_rate=0.0001,\n",
        "    # learning_rate=lambda progress: cosine_annealing_schedule(progress, \n",
        "    #     min_lr=config['min_lr'], max_lr=config['max_lr']),  # Cosine schedule\n",
        "    # batch_size=config['batch_size'],\n",
        "    # gamma=config['gamma'],\n",
        "    # tau=config['tau'],\n",
        "    # buffer_size=config['buffer_size'],\n",
        "    # learning_starts=config['learning_starts'],\n",
        "    # train_freq=config['train_freq'],\n",
        "    # action_noise=action_noise,\n",
        "    # policy_kwargs=policy_kwargs,  # Use custom policy network structure\n",
        "    seed=seed,\n",
        "    verbose=1,\n",
        "    # Adding the optimized DDPG-specific parameters to the model\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "# Create the evaluation environment\n",
        "eval_env = create_eval_env(seed)\n",
        "\n",
        "\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=save_dir,\n",
        "    log_path=save_dir,\n",
        "    eval_freq=config['check_freq'],\n",
        "    n_eval_episodes=config['n_eval_episodes'],\n",
        "    deterministic=True,\n",
        "    render=False\n",
        ")\n",
        "# Train the model with the callbacks\n",
        "model.learn(total_timesteps=config['total_timesteps'], callback=eval_callback)\n",
        "\n",
        "# Save the model\n",
        "model.save(save_dir)\n",
        "\n",
        "# Save the disturbances to a file for future reference\n",
        "disturbances_file_path = os.path.join(save_dir, \"disturbances_used_in_training.txt\")\n",
        "with open(disturbances_file_path, \"w\") as f:\n",
        "    for i, disturbance in enumerate(disturbances_list):\n",
        "        f.write(f\"Disturbance {i+1}: {disturbance}\\n\")\n",
        "\n",
        "# Finish the W&B run\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6x1u30y1uN2_"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "pcgym_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02ab575e267f4264a325dcea50170518": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d397a3c58bdb4f09b7e774b30727d8ae",
              "IPY_MODEL_5e12a8eb338042f8b42b6f9a35813403"
            ],
            "layout": "IPY_MODEL_cc9fd941a0004a3ebb1d5d66a1013aaf"
          }
        },
        "15627f8991b54e8b961444ef8481086b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a083985d3e466cb8130c07d692901c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c77ed8695a4287956ec27672fe7b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b907d9cb030400c8cd9308246d761c1",
              "IPY_MODEL_bf4a59f3065346d6af96d1fc1a2e6385"
            ],
            "layout": "IPY_MODEL_c341e0ddb94f4c0b9066e8dc99136430"
          }
        },
        "32fd32bd040841959acbae2d2e1b8365": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a6dbe39e8e492baac9782ed9b7230e",
            "placeholder": "",
            "style": "IPY_MODEL_b74942f112ea4933b0c5ba6176c6b142",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "35e1b6be6af8413d95e14d6ce68f3f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32fd32bd040841959acbae2d2e1b8365",
              "IPY_MODEL_52dbfe8dcd8d4a968987b49e4643feeb"
            ],
            "layout": "IPY_MODEL_15627f8991b54e8b961444ef8481086b"
          }
        },
        "483c79836eed4cfab4cfc7320151ef66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "518bd8accca940b284dfc562ca9b823c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52dbfe8dcd8d4a968987b49e4643feeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ce0aa2308849fb9a56cbd94aad8fa9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b5526159b14423dbcc1228e4a1f7699",
            "value": 1
          }
        },
        "5b5526159b14423dbcc1228e4a1f7699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b907d9cb030400c8cd9308246d761c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac046599192d45cfbf5ab150f9fb240d",
            "placeholder": "",
            "style": "IPY_MODEL_483c79836eed4cfab4cfc7320151ef66",
            "value": "0.674 MB of 0.674 MB uploaded\r"
          }
        },
        "5e12a8eb338042f8b42b6f9a35813403": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae728950ce914f39a035a67662e99bad",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_518bd8accca940b284dfc562ca9b823c",
            "value": 1
          }
        },
        "6446e95478cf4113aad04353ba1c2030": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac046599192d45cfbf5ab150f9fb240d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae728950ce914f39a035a67662e99bad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b74942f112ea4933b0c5ba6176c6b142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf4a59f3065346d6af96d1fc1a2e6385": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8afd67546254f249e488008aa76f0a8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6446e95478cf4113aad04353ba1c2030",
            "value": 1
          }
        },
        "c2ce0aa2308849fb9a56cbd94aad8fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c341e0ddb94f4c0b9066e8dc99136430": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc9fd941a0004a3ebb1d5d66a1013aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb98e5737c9486fb426884c14e5ae1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1a6dbe39e8e492baac9782ed9b7230e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d397a3c58bdb4f09b7e774b30727d8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a083985d3e466cb8130c07d692901c",
            "placeholder": "",
            "style": "IPY_MODEL_cfb98e5737c9486fb426884c14e5ae1f",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "e8afd67546254f249e488008aa76f0a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
